{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "039df9a7-cbce-43e7-8220-0bf4ff881dc9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "which java -> /rds/bear-apps/2024a/EL8-ice/software/Java/17.0.15/bin/java\n",
      "openjdk version \"17.0.15\" 2025-04-15\n",
      "OpenJDK Runtime Environment Temurin-17.0.15+6 (build 17.0.15+6)\n",
      "OpenJDK 64-Bit Server VM Temurin-17.0.15+6 (build 17.0.15+6, mixed mode, sharing)\n",
      "\n",
      "Checking whether there is an H2O instance running at http://localhost:54321..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "  Java Version: openjdk version \"17.0.15\" 2025-04-15; OpenJDK Runtime Environment Temurin-17.0.15+6 (build 17.0.15+6); OpenJDK 64-Bit Server VM Temurin-17.0.15+6 (build 17.0.15+6, mixed mode, sharing)\n",
      "  Starting server from /rds/homes/j/jxq370/.local/lib/python3.12/site-packages/h2o/backend/bin/h2o.jar\n",
      "  Ice root: /tmp/tmp93yiia1c\n",
      "  JVM stdout: /tmp/tmp93yiia1c/h2o_jxq370_started_from_python.out\n",
      "  JVM stderr: /tmp/tmp93yiia1c/h2o_jxq370_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:54321\n",
      "Connecting to H2O server at http://127.0.0.1:54321 ... successful.\n",
      "Warning: Your H2O cluster version is (5 months and 13 days) old.  There may be a newer version available.\n",
      "Please download and install the latest version from: https://h2o-release.s3.amazonaws.com/h2o/latest_stable.html\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "\n",
       "#h2o-table-3.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-3 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-3 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-3 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-3 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-3 .h2o-table th,\n",
       "#h2o-table-3 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-3 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-3\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption></caption>\n",
       "    <thead></thead>\n",
       "    <tbody><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>01 secs</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>Europe/London</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.46.0.7</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>5 months and 13 days</td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_jxq370_rvkv9f</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>120 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>72</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://127.0.0.1:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.12.3 final</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n"
      ],
      "text/plain": [
       "--------------------------  -----------------------------\n",
       "H2O_cluster_uptime:         01 secs\n",
       "H2O_cluster_timezone:       Europe/London\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.46.0.7\n",
       "H2O_cluster_version_age:    5 months and 13 days\n",
       "H2O_cluster_name:           H2O_from_python_jxq370_rvkv9f\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    120 Gb\n",
       "H2O_cluster_total_cores:    72\n",
       "H2O_cluster_allowed_cores:  1\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://127.0.0.1:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "Python_version:             3.12.3 final\n",
       "--------------------------  -----------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os, shutil, subprocess\n",
    "\n",
    "# Adjust this if your site uses a slightly different path:\n",
    "JAVA_HOME = \"/rds/bear-apps/2024a/EL8-ice/software/Java/17.0.15\"\n",
    "\n",
    "os.environ[\"JAVA_HOME\"] = JAVA_HOME\n",
    "os.environ[\"PATH\"] = f\"{JAVA_HOME}/bin:\" + os.environ[\"PATH\"]\n",
    "\n",
    "print(\"which java ->\", shutil.which(\"java\"))\n",
    "print(subprocess.check_output([\"java\",\"-version\"], stderr=subprocess.STDOUT).decode())\n",
    "\n",
    "import h2o\n",
    "import os\n",
    "nthreads = int(os.getenv(\"SLURM_CPUS_PER_TASK\",\"-1\"))\n",
    "h2o.init(nthreads=nthreads, max_mem_size=\"120G\", port=54321, bind_to_localhost=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be37b856-344c-41bc-8db7-03e6a37a3ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-10 11:10:28,781 - INFO - Starting Scenario Generation and Impact Prediction...\n",
      "2025-09-10 11:10:28,782 - INFO - ============================================================\n",
      "2025-09-10 11:10:28,782 - INFO - Step 1: Initializing H2O and loading model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321. connected.\n",
      "Warning: Your H2O cluster version is (5 months and 13 days) old.  There may be a newer version available.\n",
      "Please download and install the latest version from: https://h2o-release.s3.amazonaws.com/h2o/latest_stable.html\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "\n",
       "#h2o-table-4.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-4 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-4 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-4 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-4 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-4 .h2o-table th,\n",
       "#h2o-table-4 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-4 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-4\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption></caption>\n",
       "    <thead></thead>\n",
       "    <tbody><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>05 secs</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>Europe/London</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.46.0.7</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>5 months and 13 days</td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_jxq370_rvkv9f</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>120 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>72</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://localhost:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.12.3 final</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n"
      ],
      "text/plain": [
       "--------------------------  -----------------------------\n",
       "H2O_cluster_uptime:         05 secs\n",
       "H2O_cluster_timezone:       Europe/London\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.46.0.7\n",
       "H2O_cluster_version_age:    5 months and 13 days\n",
       "H2O_cluster_name:           H2O_from_python_jxq370_rvkv9f\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    120 Gb\n",
       "H2O_cluster_total_cores:    72\n",
       "H2O_cluster_allowed_cores:  1\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://localhost:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "Python_version:             3.12.3 final\n",
       "--------------------------  -----------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-10 11:10:28,802 - INFO - H2O initialized successfully\n",
      "2025-09-10 11:10:29,137 - INFO - Loaded H2O model: StackedEnsemble_BestOfFamily_1_AutoML_4_20250903_145640\n",
      "2025-09-10 11:10:29,187 - INFO - Loading feature importance from: /rds/homes/j/jxq370/shiz-wm-netzero/users/juncheng/EPC/automl/outputs/base_model_importance/combined_base_model_importance.csv\n",
      "2025-09-10 11:10:29,189 - INFO - Loaded importance for 29 features\n",
      "2025-09-10 11:10:29,190 - INFO - Top 10 most important features:\n",
      "2025-09-10 11:10:29,190 - INFO -   WALLS_ENERGY_EFF: 0.99\n",
      "2025-09-10 11:10:29,190 - INFO -   ROOF_ENERGY_EFF: 0.92\n",
      "2025-09-10 11:10:29,191 - INFO -   CONSTRUCTION_AGE_BAND: 0.70\n",
      "2025-09-10 11:10:29,191 - INFO -   MAINHEAT_ENERGY_EFF: 0.58\n",
      "2025-09-10 11:10:29,191 - INFO -   HOT_WATER_ENERGY_EFF: 0.56\n",
      "2025-09-10 11:10:29,191 - INFO -   MAIN_FUEL: 0.48\n",
      "2025-09-10 11:10:29,192 - INFO -   WINDOWS_ENERGY_EFF: 0.41\n",
      "2025-09-10 11:10:29,192 - INFO -   TOTAL_FLOOR_AREA: 0.33\n",
      "2025-09-10 11:10:29,192 - INFO -   HEAT_LOSS_CORRIDOR: 0.26\n",
      "2025-09-10 11:10:29,192 - INFO -   MAINHEATC_ENERGY_EFF: 0.21\n",
      "2025-09-10 11:10:29,193 - INFO - Step 2: Loading clustering results...\n",
      "2025-09-10 11:10:29,193 - INFO - Loading Step 2 data from: clustering_20250904_095943\n",
      "2025-09-10 11:10:29,546 - INFO - Loaded 162469 EPC C homes\n",
      "2025-09-10 11:10:29,946 - INFO - Loaded 122847 substandard homes\n",
      "2025-09-10 11:10:29,947 - INFO - Available numeric fabric features: ['WALLS_ENERGY_EFF', 'ROOF_ENERGY_EFF', 'WINDOWS_ENERGY_EFF', 'FLOOR_ENERGY_EFF']\n",
      "2025-09-10 11:10:29,947 - INFO - Available service features: ['MAINHEAT_ENERGY_EFF', 'HOT_WATER_ENERGY_EFF', 'LIGHTING_ENERGY_EFF', 'MAINHEATC_ENERGY_EFF']\n",
      "2025-09-10 11:10:29,947 - INFO - Available categorical fabric features: []\n",
      "2025-09-10 11:10:29,949 - INFO - Loaded profiles for 4 clusters\n",
      "2025-09-10 11:10:29,949 - INFO - Step 2.5: Running data diagnostics...\n",
      "2025-09-10 11:10:29,950 - INFO - \n",
      "==================================================\n",
      "2025-09-10 11:10:29,950 - INFO - DATA DIAGNOSTICS\n",
      "2025-09-10 11:10:29,950 - INFO - ==================================================\n",
      "2025-09-10 11:10:29,951 - INFO - Floor area stats:\n",
      "2025-09-10 11:10:29,951 - INFO -   Mean: 60.97\n",
      "2025-09-10 11:10:29,954 - INFO -   Median: 57.00\n",
      "2025-09-10 11:10:29,955 - INFO -   95th percentile: 108.00\n",
      "2025-09-10 11:10:29,957 - INFO -   99th percentile: 152.00\n",
      "2025-09-10 11:10:29,958 - INFO -   Max: 2862.00\n",
      "2025-09-10 11:10:29,959 - INFO - Glazing proportion stats:\n",
      "2025-09-10 11:10:29,959 - INFO -   Mean: 79.34\n",
      "2025-09-10 11:10:29,961 - INFO -   Median: 100.00\n",
      "2025-09-10 11:10:29,961 - INFO -   Max: 100.00\n",
      "2025-09-10 11:10:29,961 - WARNING -   WARNING: Glazing appears to be percentage (0-100), not ratio (0-1)!\n",
      "2025-09-10 11:10:29,962 - INFO - \n",
      "Current efficiency distributions:\n",
      "2025-09-10 11:10:29,967 - INFO - WALLS_ENERGY_EFF:\n",
      "2025-09-10 11:10:29,967 - INFO -   Mean: 1.92\n",
      "2025-09-10 11:10:29,968 - INFO -   % below Good (4): 79.1%\n",
      "2025-09-10 11:10:29,968 - INFO -   % at Very Poor (1): 55.2%\n",
      "2025-09-10 11:10:29,974 - INFO - ROOF_ENERGY_EFF:\n",
      "2025-09-10 11:10:29,974 - INFO -   Mean: 2.03\n",
      "2025-09-10 11:10:29,975 - INFO -   % below Good (4): 77.2%\n",
      "2025-09-10 11:10:29,975 - INFO -   % at Very Poor (1): 59.2%\n",
      "2025-09-10 11:10:29,981 - INFO - WINDOWS_ENERGY_EFF:\n",
      "2025-09-10 11:10:29,981 - INFO -   Mean: 2.83\n",
      "2025-09-10 11:10:29,981 - INFO -   % below Good (4): 78.5%\n",
      "2025-09-10 11:10:29,982 - INFO -   % at Very Poor (1): 17.1%\n",
      "2025-09-10 11:10:29,982 - INFO - Step 3: Computing upgrade targets...\n",
      "2025-09-10 11:10:30,125 - INFO - Computed upgrade targets for 4 clusters\n",
      "2025-09-10 11:10:30,125 - INFO - \n",
      "Cluster 0 targets:\n",
      "2025-09-10 11:10:30,125 - INFO -   A0:\n",
      "2025-09-10 11:10:30,125 - INFO -     WALLS_ENERGY_EFF: 3 (Average)\n",
      "2025-09-10 11:10:30,126 - INFO -     ROOF_ENERGY_EFF: 4.0 (Good)\n",
      "2025-09-10 11:10:30,126 - INFO -     WINDOWS_ENERGY_EFF: 3 (Average)\n",
      "2025-09-10 11:10:30,126 - INFO -     FLOOR_ENERGY_EFF: 4.0 (Good)\n",
      "2025-09-10 11:10:30,126 - INFO -     MAINHEAT_ENERGY_EFF: 4.0 (Good)\n",
      "2025-09-10 11:10:30,126 - INFO -     HOT_WATER_ENERGY_EFF: 4.0 (Good)\n",
      "2025-09-10 11:10:30,127 - INFO -     LIGHTING_ENERGY_EFF: 5.0 (Very Good)\n",
      "2025-09-10 11:10:30,127 - INFO -     MAINHEATC_ENERGY_EFF: 3.0 (Average)\n",
      "2025-09-10 11:10:30,127 - INFO -     LOW_ENERGY_LIGHTING: 80.00\n",
      "2025-09-10 11:10:30,128 - INFO -     PHOTO_SUPPLY: 0.00\n",
      "2025-09-10 11:10:30,128 - INFO -   A1:\n",
      "2025-09-10 11:10:30,128 - INFO -     WALLS_ENERGY_EFF: 4 (Good)\n",
      "2025-09-10 11:10:30,128 - INFO -     ROOF_ENERGY_EFF: 4 (Good)\n",
      "2025-09-10 11:10:30,129 - INFO -     WINDOWS_ENERGY_EFF: 4 (Good)\n",
      "2025-09-10 11:10:30,129 - INFO -     FLOOR_ENERGY_EFF: 5.0 (Very Good)\n",
      "2025-09-10 11:10:30,129 - INFO -     MAINHEAT_ENERGY_EFF: 4 (Good)\n",
      "2025-09-10 11:10:30,129 - INFO -     HOT_WATER_ENERGY_EFF: 4 (Good)\n",
      "2025-09-10 11:10:30,130 - INFO -     LIGHTING_ENERGY_EFF: 5.0 (Very Good)\n",
      "2025-09-10 11:10:30,130 - INFO -     MAINHEATC_ENERGY_EFF: 4.0 (Good)\n",
      "2025-09-10 11:10:30,130 - INFO -     LOW_ENERGY_LIGHTING: 100.00\n",
      "2025-09-10 11:10:30,130 - INFO -     PHOTO_SUPPLY: 0.00\n",
      "2025-09-10 11:10:30,131 - INFO - \n",
      "Cluster 1 targets:\n",
      "2025-09-10 11:10:30,131 - INFO -   A0:\n",
      "2025-09-10 11:10:30,131 - INFO -     WALLS_ENERGY_EFF: 4.0 (Good)\n",
      "2025-09-10 11:10:30,131 - INFO -     ROOF_ENERGY_EFF: 4.0 (Good)\n",
      "2025-09-10 11:10:30,131 - INFO -     WINDOWS_ENERGY_EFF: 3 (Average)\n",
      "2025-09-10 11:10:30,132 - INFO -     MAINHEAT_ENERGY_EFF: 4.0 (Good)\n",
      "2025-09-10 11:10:30,132 - INFO -     HOT_WATER_ENERGY_EFF: 4.0 (Good)\n",
      "2025-09-10 11:10:30,132 - INFO -     LIGHTING_ENERGY_EFF: 5.0 (Very Good)\n",
      "2025-09-10 11:10:30,133 - INFO -     MAINHEATC_ENERGY_EFF: 3.0 (Average)\n",
      "2025-09-10 11:10:30,133 - INFO -     LOW_ENERGY_LIGHTING: 100.00\n",
      "2025-09-10 11:10:30,133 - INFO -     PHOTO_SUPPLY: 0.00\n",
      "2025-09-10 11:10:30,133 - INFO -   A1:\n",
      "2025-09-10 11:10:30,133 - INFO -     WALLS_ENERGY_EFF: 4 (Good)\n",
      "2025-09-10 11:10:30,134 - INFO -     ROOF_ENERGY_EFF: 5.0 (Very Good)\n",
      "2025-09-10 11:10:30,134 - INFO -     WINDOWS_ENERGY_EFF: 4 (Good)\n",
      "2025-09-10 11:10:30,134 - INFO -     MAINHEAT_ENERGY_EFF: 4 (Good)\n",
      "2025-09-10 11:10:30,134 - INFO -     HOT_WATER_ENERGY_EFF: 4 (Good)\n",
      "2025-09-10 11:10:30,134 - INFO -     LIGHTING_ENERGY_EFF: 5.0 (Very Good)\n",
      "2025-09-10 11:10:30,135 - INFO -     MAINHEATC_ENERGY_EFF: 4.0 (Good)\n",
      "2025-09-10 11:10:30,135 - INFO -     LOW_ENERGY_LIGHTING: 100.00\n",
      "2025-09-10 11:10:30,135 - INFO -     PHOTO_SUPPLY: 0.00\n",
      "2025-09-10 11:10:30,135 - INFO - \n",
      "Cluster 2 targets:\n",
      "2025-09-10 11:10:30,135 - INFO -   A0:\n",
      "2025-09-10 11:10:30,136 - INFO -     WALLS_ENERGY_EFF: 4.0 (Good)\n",
      "2025-09-10 11:10:30,136 - INFO -     ROOF_ENERGY_EFF: 4.0 (Good)\n",
      "2025-09-10 11:10:30,136 - INFO -     WINDOWS_ENERGY_EFF: 4.0 (Good)\n",
      "2025-09-10 11:10:30,137 - INFO -     FLOOR_ENERGY_EFF: 5.0 (Very Good)\n",
      "2025-09-10 11:10:30,137 - INFO -     MAINHEAT_ENERGY_EFF: 3 (Average)\n",
      "2025-09-10 11:10:30,137 - INFO -     HOT_WATER_ENERGY_EFF: 3 (Average)\n",
      "2025-09-10 11:10:30,138 - INFO -     LIGHTING_ENERGY_EFF: 5.0 (Very Good)\n",
      "2025-09-10 11:10:30,138 - INFO -     MAINHEATC_ENERGY_EFF: 4.0 (Good)\n",
      "2025-09-10 11:10:30,138 - INFO -     LOW_ENERGY_LIGHTING: 83.00\n",
      "2025-09-10 11:10:30,138 - INFO -     PHOTO_SUPPLY: 0.00\n",
      "2025-09-10 11:10:30,138 - INFO -   A1:\n",
      "2025-09-10 11:10:30,139 - INFO -     WALLS_ENERGY_EFF: 4 (Good)\n",
      "2025-09-10 11:10:30,139 - INFO -     ROOF_ENERGY_EFF: 5.0 (Very Good)\n",
      "2025-09-10 11:10:30,139 - INFO -     WINDOWS_ENERGY_EFF: 4 (Good)\n",
      "2025-09-10 11:10:30,139 - INFO -     FLOOR_ENERGY_EFF: 5.0 (Very Good)\n",
      "2025-09-10 11:10:30,140 - INFO -     MAINHEAT_ENERGY_EFF: 4 (Good)\n",
      "2025-09-10 11:10:30,140 - INFO -     HOT_WATER_ENERGY_EFF: 4 (Good)\n",
      "2025-09-10 11:10:30,140 - INFO -     LIGHTING_ENERGY_EFF: 5.0 (Very Good)\n",
      "2025-09-10 11:10:30,140 - INFO -     MAINHEATC_ENERGY_EFF: 4.0 (Good)\n",
      "2025-09-10 11:10:30,140 - INFO -     LOW_ENERGY_LIGHTING: 100.00\n",
      "2025-09-10 11:10:30,140 - INFO -     PHOTO_SUPPLY: 0.00\n",
      "2025-09-10 11:10:30,141 - INFO - \n",
      "Cluster 3 targets:\n",
      "2025-09-10 11:10:30,141 - INFO -   A0:\n",
      "2025-09-10 11:10:30,141 - INFO -     WALLS_ENERGY_EFF: 4.0 (Good)\n",
      "2025-09-10 11:10:30,141 - INFO -     ROOF_ENERGY_EFF: 4.0 (Good)\n",
      "2025-09-10 11:10:30,141 - INFO -     WINDOWS_ENERGY_EFF: 4.0 (Good)\n",
      "2025-09-10 11:10:30,142 - INFO -     FLOOR_ENERGY_EFF: 5.0 (Very Good)\n",
      "2025-09-10 11:10:30,142 - INFO -     MAINHEAT_ENERGY_EFF: 4.0 (Good)\n",
      "2025-09-10 11:10:30,142 - INFO -     HOT_WATER_ENERGY_EFF: 4.0 (Good)\n",
      "2025-09-10 11:10:30,142 - INFO -     LIGHTING_ENERGY_EFF: 5.0 (Very Good)\n",
      "2025-09-10 11:10:30,142 - INFO -     MAINHEATC_ENERGY_EFF: 4.0 (Good)\n",
      "2025-09-10 11:10:30,143 - INFO -     LOW_ENERGY_LIGHTING: 100.00\n",
      "2025-09-10 11:10:30,143 - INFO -     PHOTO_SUPPLY: 0.00\n",
      "2025-09-10 11:10:30,143 - INFO -   A1:\n",
      "2025-09-10 11:10:30,143 - INFO -     WALLS_ENERGY_EFF: 4 (Good)\n",
      "2025-09-10 11:10:30,143 - INFO -     ROOF_ENERGY_EFF: 4 (Good)\n",
      "2025-09-10 11:10:30,144 - INFO -     WINDOWS_ENERGY_EFF: 4 (Good)\n",
      "2025-09-10 11:10:30,144 - INFO -     FLOOR_ENERGY_EFF: 5.0 (Very Good)\n",
      "2025-09-10 11:10:30,144 - INFO -     MAINHEAT_ENERGY_EFF: 4 (Good)\n",
      "2025-09-10 11:10:30,144 - INFO -     HOT_WATER_ENERGY_EFF: 4 (Good)\n",
      "2025-09-10 11:10:30,144 - INFO -     LIGHTING_ENERGY_EFF: 5.0 (Very Good)\n",
      "2025-09-10 11:10:30,145 - INFO -     MAINHEATC_ENERGY_EFF: 4.0 (Good)\n",
      "2025-09-10 11:10:30,145 - INFO -     LOW_ENERGY_LIGHTING: 100.00\n",
      "2025-09-10 11:10:30,145 - INFO -     PHOTO_SUPPLY: 0.00\n",
      "2025-09-10 11:10:30,150 - INFO - Step 4: Creating upgrade scenarios...\n",
      "2025-09-10 11:50:20,558 - INFO - \n",
      "============================================================\n",
      "2025-09-10 11:50:20,559 - INFO - UPGRADE APPLICATION STATISTICS\n",
      "2025-09-10 11:50:20,559 - INFO - ============================================================\n",
      "2025-09-10 11:50:20,698 - INFO - \n",
      "A0 (Moderate) upgrades applied:\n",
      "2025-09-10 11:50:20,698 - INFO -   WALLS_ENERGY_EFF: 96411 homes (78.5%)\n",
      "2025-09-10 11:50:20,699 - INFO -   WINDOWS_ENERGY_EFF: 90544 homes (73.7%)\n",
      "2025-09-10 11:50:20,699 - INFO -   LOW_ENERGY_LIGHTING: 86262 homes (70.2%)\n",
      "2025-09-10 11:50:20,699 - INFO -   LIGHTING_ENERGY_EFF: 72638 homes (59.1%)\n",
      "2025-09-10 11:50:20,699 - INFO -   MAINHEATC_ENERGY_EFF: 64557 homes (52.6%)\n",
      "2025-09-10 11:50:20,699 - INFO -   ROOF_ENERGY_EFF: 63763 homes (51.9%)\n",
      "2025-09-10 11:50:20,700 - INFO -   HOT_WATER_ENERGY_EFF: 60192 homes (49.0%)\n",
      "2025-09-10 11:50:20,700 - INFO -   MAINHEAT_ENERGY_EFF: 51011 homes (41.5%)\n",
      "2025-09-10 11:50:20,700 - INFO -   FLOOR_ENERGY_EFF: 240 homes (0.2%)\n",
      "2025-09-10 11:50:20,700 - INFO - \n",
      "A1 (Ambitious) upgrades applied:\n",
      "2025-09-10 11:50:20,700 - INFO -   WALLS_ENERGY_EFF: 97102 homes (79.0%)\n",
      "2025-09-10 11:50:20,701 - INFO -   WINDOWS_ENERGY_EFF: 96453 homes (78.5%)\n",
      "2025-09-10 11:50:20,701 - INFO -   LOW_ENERGY_LIGHTING: 88520 homes (72.1%)\n",
      "2025-09-10 11:50:20,701 - INFO -   MAINHEATC_ENERGY_EFF: 73524 homes (59.9%)\n",
      "2025-09-10 11:50:20,701 - INFO -   LIGHTING_ENERGY_EFF: 72638 homes (59.1%)\n",
      "2025-09-10 11:50:20,701 - INFO -   ROOF_ENERGY_EFF: 69606 homes (56.7%)\n",
      "2025-09-10 11:50:20,702 - INFO -   HOT_WATER_ENERGY_EFF: 64249 homes (52.3%)\n",
      "2025-09-10 11:50:20,702 - INFO -   MAINHEAT_ENERGY_EFF: 57155 homes (46.5%)\n",
      "2025-09-10 11:50:20,702 - INFO -   FLOOR_ENERGY_EFF: 240 homes (0.2%)\n",
      "2025-09-10 11:50:20,702 - INFO - \n",
      "Additional upgrades in A1 vs A0:\n",
      "2025-09-10 11:50:20,702 - INFO -   MAINHEATC_ENERGY_EFF: +8967 homes\n",
      "2025-09-10 11:50:20,703 - INFO -   MAINHEAT_ENERGY_EFF: +6144 homes\n",
      "2025-09-10 11:50:20,703 - INFO -   WINDOWS_ENERGY_EFF: +5909 homes\n",
      "2025-09-10 11:50:20,703 - INFO -   ROOF_ENERGY_EFF: +5843 homes\n",
      "2025-09-10 11:50:20,703 - INFO -   HOT_WATER_ENERGY_EFF: +4057 homes\n",
      "2025-09-10 11:50:20,703 - INFO -   LOW_ENERGY_LIGHTING: +2258 homes\n",
      "2025-09-10 11:50:20,703 - INFO -   WALLS_ENERGY_EFF: +691 homes\n",
      "2025-09-10 11:50:20,710 - INFO - Step 5: Predicting scenario outcomes...\n",
      "2025-09-10 11:50:20,711 - INFO - Predicting outcomes for scenarios...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "stackedensemble prediction progress: |███████████████████████████████████████████| (done) 100%\n",
      "stackedensemble prediction progress: |███████████████████████████████████████████| (done) 100%\n",
      "stackedensemble prediction progress: |███████████████████████████████████████████| (done) 100%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-10 11:50:34,983 - INFO - Scenario predictions completed\n",
      "2025-09-10 11:50:34,983 - INFO - \n",
      "============================================================\n",
      "2025-09-10 11:50:34,984 - INFO - PREDICTION SUMMARY\n",
      "2025-09-10 11:50:34,984 - INFO - ============================================================\n",
      "2025-09-10 11:50:34,984 - INFO - \n",
      "A0 (Moderate) Scenario:\n",
      "2025-09-10 11:50:34,988 - INFO -   Homes improved: 122571/122847 (99.8%)\n",
      "2025-09-10 11:50:34,988 - INFO -   Achieved C or better: 121614/122847 (99.0%)\n",
      "2025-09-10 11:50:34,989 - INFO -   Mean improvement: 1.52 bands\n",
      "2025-09-10 11:50:34,989 - INFO - \n",
      "A1 (Ambitious) Scenario:\n",
      "2025-09-10 11:50:34,993 - INFO -   Homes improved: 122847/122847 (100.0%)\n",
      "2025-09-10 11:50:34,993 - INFO -   Achieved C or better: 122847/122847 (100.0%)\n",
      "2025-09-10 11:50:34,994 - INFO -   Mean improvement: 1.53 bands\n",
      "2025-09-10 11:50:35,084 - INFO - Step 6: Calculating costs and benefits...\n",
      "2025-09-10 11:50:35,085 - INFO - Calculating costs and benefits...\n",
      "2025-09-10 11:50:57,872 - INFO - \n",
      "============================================================\n",
      "2025-09-10 11:50:57,873 - INFO - COST-BENEFIT SUMMARY\n",
      "2025-09-10 11:50:57,873 - INFO - ============================================================\n",
      "2025-09-10 11:50:57,873 - INFO - \n",
      "A0 (Moderate) Scenario:\n",
      "2025-09-10 11:50:57,874 - INFO -   Average cost: £28,200.09\n",
      "2025-09-10 11:50:57,877 - INFO -   Median cost: £24,333.12\n",
      "2025-09-10 11:50:57,877 - INFO -   Average annual savings: £1,223.89\n",
      "2025-09-10 11:50:57,882 - INFO -   Average payback period: 21.3 years\n",
      "2025-09-10 11:50:57,884 - INFO -   Median payback period: 21.9 years\n",
      "2025-09-10 11:50:57,884 - INFO -   Cost per rating improvement: £21,181.92\n",
      "2025-09-10 11:50:57,885 - INFO - \n",
      "A1 (Ambitious) Scenario:\n",
      "2025-09-10 11:50:57,885 - INFO -   Average cost: £29,426.87\n",
      "2025-09-10 11:50:57,887 - INFO -   Median cost: £26,212.00\n",
      "2025-09-10 11:50:57,888 - INFO -   Average annual savings: £1,237.50\n",
      "2025-09-10 11:50:57,892 - INFO -   Average payback period: 22.5 years\n",
      "2025-09-10 11:50:57,894 - INFO -   Median payback period: 22.6 years\n",
      "2025-09-10 11:50:57,894 - INFO -   Cost per rating improvement: £22,164.79\n",
      "2025-09-10 11:50:57,933 - INFO - Step 6.5: Analyzing costs by rating band...\n",
      "2025-09-10 11:50:57,933 - INFO - Calculating average costs by rating band...\n",
      "2025-09-10 11:50:57,989 - INFO - \n",
      "============================================================\n",
      "2025-09-10 11:50:57,989 - INFO - COST ANALYSIS BY INITIAL RATING\n",
      "2025-09-10 11:50:57,989 - INFO - ============================================================\n",
      "2025-09-10 11:50:57,990 - INFO - \n",
      "Rating D → C:\n",
      "2025-09-10 11:50:57,990 - INFO -   Total homes: 78937\n",
      "2025-09-10 11:50:57,990 - INFO -   A0 (Moderate):\n",
      "2025-09-10 11:50:57,990 - INFO -     Average cost: £24,975.45\n",
      "2025-09-10 11:50:57,990 - INFO -     Success rate: 99.7%\n",
      "2025-09-10 11:50:57,991 - INFO -     Cost per success: £24,976.18\n",
      "2025-09-10 11:50:57,991 - INFO -   A1 (Ambitious):\n",
      "2025-09-10 11:50:57,991 - INFO -     Average cost: £26,559.52\n",
      "2025-09-10 11:50:57,991 - INFO -     Success rate: 100.0%\n",
      "2025-09-10 11:50:57,991 - INFO -     Cost per success: £26,559.52\n",
      "2025-09-10 11:50:57,992 - INFO - \n",
      "Rating E → C:\n",
      "2025-09-10 11:50:57,992 - INFO -   Total homes: 33519\n",
      "2025-09-10 11:50:57,992 - INFO -   A0 (Moderate):\n",
      "2025-09-10 11:50:57,992 - INFO -     Average cost: £33,863.82\n",
      "2025-09-10 11:50:57,992 - INFO -     Success rate: 98.6%\n",
      "2025-09-10 11:50:57,993 - INFO -     Cost per success: £33,949.50\n",
      "2025-09-10 11:50:57,993 - INFO -   A1 (Ambitious):\n",
      "2025-09-10 11:50:57,993 - INFO -     Average cost: £34,560.28\n",
      "2025-09-10 11:50:57,993 - INFO -     Success rate: 100.0%\n",
      "2025-09-10 11:50:57,993 - INFO -     Cost per success: £34,560.28\n",
      "2025-09-10 11:50:57,994 - INFO - \n",
      "Rating F → C:\n",
      "2025-09-10 11:50:57,995 - INFO -   Total homes: 7314\n",
      "2025-09-10 11:50:57,995 - INFO -   A0 (Moderate):\n",
      "2025-09-10 11:50:57,995 - INFO -     Average cost: £32,826.45\n",
      "2025-09-10 11:50:57,995 - INFO -     Success rate: 95.8%\n",
      "2025-09-10 11:50:57,995 - INFO -     Cost per success: £32,958.77\n",
      "2025-09-10 11:50:57,996 - INFO -   A1 (Ambitious):\n",
      "2025-09-10 11:50:57,996 - INFO -     Average cost: £33,089.26\n",
      "2025-09-10 11:50:57,996 - INFO -     Success rate: 100.0%\n",
      "2025-09-10 11:50:57,996 - INFO -     Cost per success: £33,089.26\n",
      "2025-09-10 11:50:57,996 - INFO - \n",
      "Rating G → C:\n",
      "2025-09-10 11:50:57,997 - INFO -   Total homes: 3077\n",
      "2025-09-10 11:50:57,997 - INFO -   A0 (Moderate):\n",
      "2025-09-10 11:50:57,997 - INFO -     Average cost: £38,230.41\n",
      "2025-09-10 11:50:57,997 - INFO -     Success rate: 94.5%\n",
      "2025-09-10 11:50:57,997 - INFO -     Cost per success: £38,731.05\n",
      "2025-09-10 11:50:57,998 - INFO -   A1 (Ambitious):\n",
      "2025-09-10 11:50:57,998 - INFO -     Average cost: £38,359.73\n",
      "2025-09-10 11:50:57,998 - INFO -     Success rate: 100.0%\n",
      "2025-09-10 11:50:57,998 - INFO -     Cost per success: £38,359.73\n",
      "2025-09-10 11:50:57,998 - INFO - \n",
      "KEY INSIGHTS:\n",
      "2025-09-10 11:50:57,999 - INFO - \n",
      "Cost multipliers relative to D→C upgrade:\n",
      "2025-09-10 11:50:57,999 - INFO -   E→C costs 1.4x more than D→C (A0)\n",
      "2025-09-10 11:50:57,999 - INFO -   F→C costs 1.3x more than D→C (A0)\n",
      "2025-09-10 11:50:57,999 - INFO -   G→C costs 1.5x more than D→C (A0)\n",
      "2025-09-10 11:50:58,000 - INFO - \n",
      "Most cost-effective upgrades:\n",
      "2025-09-10 11:50:58,001 - INFO -   A0: D→C (£24,976 per success)\n",
      "2025-09-10 11:50:58,001 - INFO -   A1: D→C (£26,560 per success)\n",
      "2025-09-10 11:50:59,150 - INFO - Rating band cost visualization saved\n",
      "2025-09-10 11:50:59,151 - INFO - Step 7: Generating visualizations...\n",
      "2025-09-10 11:51:02,493 - INFO - Visualizations generated successfully\n",
      "2025-09-10 11:51:02,494 - INFO - Step 8: Saving results...\n",
      "2025-09-10 11:51:02,494 - INFO - Saving results...\n",
      "2025-09-10 11:51:10,302 - INFO - All results saved to: /rds/homes/j/jxq370/shiz-wm-netzero/users/juncheng/EPC/outputs/step_3_scenarios/scenarios_20250910_111028\n",
      "2025-09-10 11:51:10,302 - INFO - Step 9: Generating final report...\n",
      "2025-09-10 11:51:10,362 - INFO - Report saved to: /rds/homes/j/jxq370/shiz-wm-netzero/users/juncheng/EPC/outputs/step_3_scenarios/scenarios_20250910_111028/scenario_analysis_report_20250910_111028.txt\n",
      "2025-09-10 11:51:10,362 - INFO - \n",
      "============================================================\n",
      "2025-09-10 11:51:10,363 - INFO - SCENARIO ANALYSIS COMPLETE\n",
      "2025-09-10 11:51:10,363 - INFO - ============================================================\n",
      "2025-09-10 11:51:10,363 - INFO - Results saved to: /rds/homes/j/jxq370/shiz-wm-netzero/users/juncheng/EPC/outputs/step_3_scenarios/scenarios_20250910_111028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H2O session _sid_97a6 closed.\n",
      "\n",
      "============================================================\n",
      "SCENARIO ANALYSIS COMPLETED SUCCESSFULLY!\n",
      "============================================================\n",
      "Homes analyzed: 122847\n",
      "A0 success rate: 99.0%\n",
      "A1 success rate: 100.0%\n",
      "A0 average cost: £28,200.09\n",
      "A1 average cost: £29,426.87\n",
      "Feature importance loaded: True\n",
      "Rating band analysis completed: True\n",
      "Results saved to: /rds/homes/j/jxq370/shiz-wm-netzero/users/juncheng/EPC/outputs/step_3_scenarios/scenarios_20250910_111028\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "EPC Step 3: Scenario Generation and Impact Prediction \n",
    "======================================================================\n",
    "\n",
    "This script generates upgrade scenarios for sub-standard homes using:\n",
    "1. H2O AutoML model from Step 1 to predict EPC rating improvements\n",
    "2. Clustering results from Step 2 to identify upgrade pathways\n",
    "3. Cost-benefit analysis of proposed upgrades\n",
    "4. Analysis of upgrade costs by initial rating band (D→C, E→C, F→C, G→C)\n",
    "\n",
    "CRITICAL FIXES APPLIED:\n",
    "- Fixed upgrade persistence (using .loc instead of .iloc)\n",
    "- Fixed glazing proportion scaling (percentage to ratio conversion)\n",
    "- Ensured A1 > A0 with sensible minimum targets\n",
    "- Linked description scores to actual efficiency changes\n",
    "- Added data diagnostics\n",
    "- Realistic cost calculations\n",
    "- Added rating band cost analysis\n",
    "\n",
    "Author: [Your Name]\n",
    "Date: [Current Date]\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "import json\n",
    "import logging\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Optional, Any\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h2o\n",
    "from h2o import H2OFrame\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# --------------------------- CONFIG ------------------------------------------\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    \"\"\"Configuration for Step 3 scenario generation.\"\"\"\n",
    "    \n",
    "    # Step-2 outputs directory\n",
    "    step2_dir: str = \"~/shiz-wm-netzero/users/juncheng/EPC/outputs/step_2_clustering\"\n",
    "    \n",
    "    # Step-1 outputs directory (for feature importance)\n",
    "    step1_dir: str = \"~/shiz-wm-netzero/users/juncheng/EPC/automl/outputs/base_model_importance\"\n",
    "    \n",
    "    # Step-1 H2O model directory\n",
    "    h2o_model_dir: str = \"~/shiz-wm-netzero/users/juncheng/EPC/automl/outputs/epc_automl_model\"\n",
    "    \n",
    "    # Step-3 outputs directory\n",
    "    output_dir: str = \"~/shiz-wm-netzero/users/juncheng/EPC/outputs/step_3_scenarios\"\n",
    "    \n",
    "    # H2O settings\n",
    "    h2o_port: str = \"54321\"\n",
    "    h2o_memory: str = \"256G\"\n",
    "    \n",
    "    # Scenario parameters\n",
    "    a0_percentile: int = 60  # Moderate upgrades (60th percentile of C-rated homes)\n",
    "    a1_percentile: int = 85  # Ambitious upgrades (85th percentile of C-rated homes)\n",
    "    \n",
    "    # Cost parameters (£ per unit)\n",
    "    costs: Dict[str, float] = field(default_factory=lambda: {\n",
    "        'wall_insulation_cavity': 15.0,  # per sqm\n",
    "        'wall_insulation_solid': 100.0,  # per sqm\n",
    "        'roof_insulation': 25.0,  # per sqm\n",
    "        'floor_insulation': 40.0,  # per sqm\n",
    "        'double_glazing': 350.0,  # per sqm\n",
    "        'heating_system_upgrade': 3500.0,  # per dwelling\n",
    "        'hot_water_upgrade': 1500.0,  # per dwelling\n",
    "        'lighting_upgrade': 200.0,  # per dwelling\n",
    "    })\n",
    "    \n",
    "    # Energy price assumptions\n",
    "    energy_price_per_kwh: float = 0.28  # £/kWh (2024 prices)\n",
    "    \n",
    "    # All upgradeable features (not dependent on importance)\n",
    "    numeric_fabric_features: List[str] = field(default_factory=lambda: [\n",
    "        \"WALLS_ENERGY_EFF\", \"ROOF_ENERGY_EFF\", \"WINDOWS_ENERGY_EFF\", \"FLOOR_ENERGY_EFF\"\n",
    "    ])\n",
    "    \n",
    "    service_features: List[str] = field(default_factory=lambda: [\n",
    "        \"MAINHEAT_ENERGY_EFF\", \"HOT_WATER_ENERGY_EFF\", \"LIGHTING_ENERGY_EFF\", \"MAINHEATC_ENERGY_EFF\"\n",
    "    ])\n",
    "    \n",
    "    categorical_fabric_features: List[str] = field(default_factory=lambda: [\n",
    "        \"ROOF_DESCRIPTION\", \"WALLS_DESCRIPTION\", \"FLOOR_DESCRIPTION\"\n",
    "    ])\n",
    "    \n",
    "    numerical_features: List[str] = field(default_factory=lambda: [\n",
    "        \"TOTAL_FLOOR_AREA\", \"LOW_ENERGY_LIGHTING\", \"FLOOR_HEIGHT\",\n",
    "        \"PHOTO_SUPPLY\", \"MULTI_GLAZE_PROPORTION\"\n",
    "    ])\n",
    "    \n",
    "    categorical_features: List[str] = field(default_factory=lambda: [\n",
    "        \"PROPERTY_TYPE\", \"ENERGY_TARIFF\", \"FLAT_TOP_STOREY\",\n",
    "        \"HEAT_LOSS_CORRIDOR\", \"MAIN_FUEL\", \"CONSTRUCTION_AGE_BAND\",\n",
    "        \"TENURE\", \"SECONDHEAT_DESCRIPTION\"\n",
    "    ])\n",
    "\n",
    "\n",
    "class ScenarioGenerator:\n",
    "    \"\"\"Main class for scenario generation and impact prediction.\"\"\"\n",
    "    \n",
    "    def __init__(self, config: Config):\n",
    "        \"\"\"Initialize the scenario generator.\"\"\"\n",
    "        self.config = config\n",
    "        self.setup_logging()\n",
    "        self.setup_directories()\n",
    "        \n",
    "        # Data containers\n",
    "        self.epc_c_data: Optional[pd.DataFrame] = None\n",
    "        self.substandard_data: Optional[pd.DataFrame] = None\n",
    "        self.h2o_model = None\n",
    "        self.feature_importance: Optional[pd.DataFrame] = None\n",
    "        self.cluster_profiles: Optional[pd.DataFrame] = None\n",
    "        \n",
    "        # Track available features\n",
    "        self.available_numeric_fabric: List[str] = []\n",
    "        self.available_service: List[str] = []\n",
    "        self.available_categorical_fabric: List[str] = []\n",
    "        \n",
    "        # Results containers\n",
    "        self.baseline_df: Optional[pd.DataFrame] = None\n",
    "        self.a0_scenario_df: Optional[pd.DataFrame] = None\n",
    "        self.a1_scenario_df: Optional[pd.DataFrame] = None\n",
    "        self.cost_benefit_df: Optional[pd.DataFrame] = None\n",
    "        self.rating_cost_df: Optional[pd.DataFrame] = None\n",
    "    \n",
    "    def setup_logging(self) -> None:\n",
    "        \"\"\"Setup logging configuration.\"\"\"\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        self.run_timestamp = timestamp\n",
    "        \n",
    "        # Create output directory for this run\n",
    "        self.run_output_dir = Path(self.config.output_dir).expanduser() / f\"scenarios_{timestamp}\"\n",
    "        self.run_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        logging.basicConfig(\n",
    "            level=logging.INFO,\n",
    "            format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "            handlers=[\n",
    "                logging.FileHandler(self.run_output_dir / 'scenario_generation.log'),\n",
    "                logging.StreamHandler()\n",
    "            ]\n",
    "        )\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "    \n",
    "    def setup_directories(self) -> None:\n",
    "        \"\"\"Create output directories.\"\"\"\n",
    "        self.plots_dir = self.run_output_dir / \"plots\"\n",
    "        self.results_dir = self.run_output_dir / \"results\"\n",
    "        \n",
    "        for directory in [self.plots_dir, self.results_dir]:\n",
    "            directory.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    def init_h2o(self) -> None:\n",
    "        \"\"\"Initialize H2O and load the AutoML model.\"\"\"\n",
    "        try:\n",
    "            # Initialize H2O\n",
    "            h2o.init(\n",
    "                port=self.config.h2o_port,\n",
    "                max_mem_size=self.config.h2o_memory,\n",
    "                nthreads=-1\n",
    "            )\n",
    "            self.logger.info(\"H2O initialized successfully\")\n",
    "            \n",
    "            # Find and load the saved model\n",
    "            model_dir = Path(self.config.h2o_model_dir).expanduser()\n",
    "            model_files = list(model_dir.glob(\"*\"))\n",
    "            \n",
    "            if not model_files:\n",
    "                raise FileNotFoundError(f\"No model found in {model_dir}\")\n",
    "            \n",
    "            # Load the first model found (should be the best model from Step 1)\n",
    "            model_path = str(model_files[0])\n",
    "            self.h2o_model = h2o.load_model(model_path)\n",
    "            self.logger.info(f\"Loaded H2O model: {self.h2o_model.model_id}\")\n",
    "            \n",
    "            # Load feature importance from saved CSV file\n",
    "            self._load_feature_importance_from_csv()\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Failed to initialize H2O or load model: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def _load_feature_importance_from_csv(self) -> None:\n",
    "        \"\"\"Load feature importance from the saved CSV file from Step 1.\"\"\"\n",
    "        try:\n",
    "            # Try multiple possible locations for the feature importance file\n",
    "            possible_paths = [\n",
    "                Path(self.config.step1_dir).expanduser() / 'combined_base_model_importance.csv',\n",
    "                Path(self.config.step1_dir).expanduser() / 'feature_importance.csv',\n",
    "                Path(\"~/shiz-wm-netzero/users/juncheng/EPC/automl/outputs/base_model_importance\").expanduser() / 'combined_base_model_importance.csv'\n",
    "            ]\n",
    "            \n",
    "            importance_file = None\n",
    "            for path in possible_paths:\n",
    "                if path.exists():\n",
    "                    importance_file = path\n",
    "                    break\n",
    "            \n",
    "            if importance_file is None:\n",
    "                self.logger.warning(\"Feature importance file not found in expected locations\")\n",
    "                self.logger.info(\"Will proceed without feature importance (all features will be treated equally)\")\n",
    "                return\n",
    "            \n",
    "            self.logger.info(f\"Loading feature importance from: {importance_file}\")\n",
    "            \n",
    "            # Load the feature importance\n",
    "            self.feature_importance = pd.read_csv(importance_file)\n",
    "            \n",
    "            # Check if the expected columns exist\n",
    "            if 'feature' in self.feature_importance.columns and 'mean_importance' in self.feature_importance.columns:\n",
    "                # Ensure that the importance columns are numeric\n",
    "                self.feature_importance['mean_importance'] = pd.to_numeric(\n",
    "                    self.feature_importance['mean_importance'], errors='coerce'\n",
    "                )\n",
    "                \n",
    "                # Sort the data by mean importance in descending order\n",
    "                self.feature_importance = self.feature_importance.sort_values(\n",
    "                    by='mean_importance', ascending=False\n",
    "                )\n",
    "                \n",
    "                self.logger.info(f\"Loaded importance for {len(self.feature_importance)} features\")\n",
    "                \n",
    "                # Log top 10 features\n",
    "                self.logger.info(\"Top 10 most important features:\")\n",
    "                for i, row in self.feature_importance.head(10).iterrows():\n",
    "                    self.logger.info(f\"  {row['feature']}: {row['mean_importance']:.2f}\")\n",
    "            else:\n",
    "                self.logger.warning(\"Feature importance file missing required columns\")\n",
    "                self.feature_importance = None\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.warning(f\"Could not load feature importance from CSV: {e}\")\n",
    "            self.logger.info(\"Will proceed without feature importance (all features will be treated equally)\")\n",
    "            self.feature_importance = None\n",
    "    \n",
    "    def load_step2_data(self) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "        \"\"\"Load the latest clustering results from Step 2.\"\"\"\n",
    "        step2_dir = Path(self.config.step2_dir).expanduser()\n",
    "        \n",
    "        # Find the most recent clustering run\n",
    "        run_dirs = sorted(step2_dir.glob(\"clustering_*\"))\n",
    "        if not run_dirs:\n",
    "            raise FileNotFoundError(f\"No clustering results found in {step2_dir}\")\n",
    "        \n",
    "        latest_dir = run_dirs[-1]\n",
    "        results_dir = latest_dir / \"results\"\n",
    "        \n",
    "        self.logger.info(f\"Loading Step 2 data from: {latest_dir.name}\")\n",
    "        \n",
    "        # Load EPC C clustered data\n",
    "        epc_c_files = list(results_dir.glob(\"epc_c_clustered_*.csv\"))\n",
    "        if not epc_c_files:\n",
    "            raise FileNotFoundError(\"No EPC C clustered data found\")\n",
    "        \n",
    "        epc_c_data = pd.read_csv(epc_c_files[-1])\n",
    "        self.logger.info(f\"Loaded {len(epc_c_data)} EPC C homes\")\n",
    "        \n",
    "        # Load substandard matched data\n",
    "        substandard_files = list(results_dir.glob(\"substandard_matched_*.csv\"))\n",
    "        if not substandard_files:\n",
    "            raise FileNotFoundError(\"No substandard matched data found\")\n",
    "        \n",
    "        substandard_data = pd.read_csv(substandard_files[-1])\n",
    "        self.logger.info(f\"Loaded {len(substandard_data)} substandard homes\")\n",
    "        \n",
    "        # Identify available upgradeable features\n",
    "        self._identify_available_features(epc_c_data)\n",
    "        \n",
    "        # Load cluster profiles if available\n",
    "        profile_files = list(results_dir.glob(\"cluster_profiles_*.csv\"))\n",
    "        if profile_files:\n",
    "            self.cluster_profiles = pd.read_csv(profile_files[-1])\n",
    "            self.logger.info(f\"Loaded profiles for {len(self.cluster_profiles)} clusters\")\n",
    "        \n",
    "        return epc_c_data, substandard_data\n",
    "    \n",
    "    def _identify_available_features(self, df: pd.DataFrame) -> None:\n",
    "        \"\"\"Identify which upgradeable features are available in the data.\"\"\"\n",
    "        # Check numeric fabric features\n",
    "        self.available_numeric_fabric = [\n",
    "            f for f in self.config.numeric_fabric_features \n",
    "            if f in df.columns\n",
    "        ]\n",
    "        self.logger.info(f\"Available numeric fabric features: {self.available_numeric_fabric}\")\n",
    "        \n",
    "        # Check service features\n",
    "        self.available_service = [\n",
    "            f for f in self.config.service_features \n",
    "            if f in df.columns\n",
    "        ]\n",
    "        self.logger.info(f\"Available service features: {self.available_service}\")\n",
    "        \n",
    "        # Check categorical fabric features\n",
    "        self.available_categorical_fabric = [\n",
    "            f for f in self.config.categorical_fabric_features \n",
    "            if f in df.columns\n",
    "        ]\n",
    "        self.logger.info(f\"Available categorical fabric features: {self.available_categorical_fabric}\")\n",
    "    \n",
    "    def diagnose_data(self):\n",
    "        \"\"\"Run diagnostics on the data to catch issues early.\"\"\"\n",
    "        self.logger.info(\"\\n\" + \"=\"*50)\n",
    "        self.logger.info(\"DATA DIAGNOSTICS\")\n",
    "        self.logger.info(\"=\"*50)\n",
    "        \n",
    "        # Check floor area distribution\n",
    "        floor_areas = pd.to_numeric(self.substandard_data['TOTAL_FLOOR_AREA'], errors='coerce')\n",
    "        self.logger.info(f\"Floor area stats:\")\n",
    "        self.logger.info(f\"  Mean: {floor_areas.mean():.2f}\")\n",
    "        self.logger.info(f\"  Median: {floor_areas.median():.2f}\")\n",
    "        self.logger.info(f\"  95th percentile: {floor_areas.quantile(0.95):.2f}\")\n",
    "        self.logger.info(f\"  99th percentile: {floor_areas.quantile(0.99):.2f}\")\n",
    "        self.logger.info(f\"  Max: {floor_areas.max():.2f}\")\n",
    "        \n",
    "        if floor_areas.mean() > 500:\n",
    "            self.logger.warning(\"  WARNING: Floor areas may be in square feet, not square meters!\")\n",
    "        \n",
    "        # Check glazing proportion\n",
    "        if 'MULTI_GLAZE_PROPORTION' in self.substandard_data.columns:\n",
    "            glazing = pd.to_numeric(self.substandard_data['MULTI_GLAZE_PROPORTION'], errors='coerce')\n",
    "            if len(glazing.dropna()) > 0:\n",
    "                self.logger.info(f\"Glazing proportion stats:\")\n",
    "                self.logger.info(f\"  Mean: {glazing.mean():.2f}\")\n",
    "                self.logger.info(f\"  Median: {glazing.median():.2f}\")\n",
    "                self.logger.info(f\"  Max: {glazing.max():.2f}\")\n",
    "                if glazing.mean() > 1:\n",
    "                    self.logger.warning(\"  WARNING: Glazing appears to be percentage (0-100), not ratio (0-1)!\")\n",
    "        \n",
    "        # Check current efficiency distributions\n",
    "        self.logger.info(\"\\nCurrent efficiency distributions:\")\n",
    "        for feature in self.available_numeric_fabric[:3]:\n",
    "            numeric_vals = self._convert_efficiency_to_numeric(self.substandard_data[feature])\n",
    "            valid_vals = numeric_vals.dropna()\n",
    "            if len(valid_vals) > 0:\n",
    "                self.logger.info(f\"{feature}:\")\n",
    "                self.logger.info(f\"  Mean: {valid_vals.mean():.2f}\")\n",
    "                self.logger.info(f\"  % below Good (4): {(valid_vals < 4).mean()*100:.1f}%\")\n",
    "                self.logger.info(f\"  % at Very Poor (1): {(valid_vals == 1).mean()*100:.1f}%\")\n",
    "    \n",
    "    # Improved description scoring functions\n",
    "    \n",
    "    def _has_negative_insulation(self, text: str) -> bool:\n",
    "        \"\"\"Check if text contains negative insulation mentions.\"\"\"\n",
    "        negative_patterns = [\n",
    "            \"no insulation\", \"not insulated\", \"uninsulated\", \n",
    "            \"without insulation\", \"no loft insulation\"\n",
    "        ]\n",
    "        return any(pattern in text for pattern in negative_patterns)\n",
    "    \n",
    "    def _extract_uvalue(self, text: str) -> Optional[float]:\n",
    "        \"\"\"Extract U-value from text (tolerant of encoding issues).\"\"\"\n",
    "        # Match patterns like \"0.25 W/m²K\" or \"0.25 w/m-2k\"\n",
    "        match = re.search(r'(\\d+(?:\\.\\d+)?)\\s*w/m', text)\n",
    "        if match:\n",
    "            try:\n",
    "                return float(match.group(1))\n",
    "            except ValueError:\n",
    "                return None\n",
    "        return None\n",
    "    \n",
    "    def score_roof_desc(self, txt: Any) -> float:\n",
    "        \"\"\"Score roof description (0-2 scale) with robust parsing.\"\"\"\n",
    "        if pd.isna(txt) or not isinstance(txt, str):\n",
    "            return 0.0\n",
    "        \n",
    "        t = txt.lower()\n",
    "        \n",
    "        # Check for negative mentions first\n",
    "        if self._has_negative_insulation(t):\n",
    "            return 0.0\n",
    "        \n",
    "        # Check for partial/limited insulation\n",
    "        if \"partial\" in t or \"limited\" in t:\n",
    "            return 0.5\n",
    "        \n",
    "        # Check U-values (roof thresholds)\n",
    "        u_value = self._extract_uvalue(t)\n",
    "        if u_value is not None:\n",
    "            if u_value <= 0.12:\n",
    "                return 2.0  # Excellent\n",
    "            elif u_value <= 0.16:\n",
    "                return 1.5  # Good\n",
    "            elif u_value <= 0.25:\n",
    "                return 1.0  # Moderate\n",
    "            else:\n",
    "                return 0.5  # Poor but present\n",
    "        \n",
    "        # Check thickness patterns\n",
    "        thickness_match = re.search(r'\\b(\\d{2,3})\\s*mm\\b', t)\n",
    "        if thickness_match:\n",
    "            thickness = int(thickness_match.group(1))\n",
    "            if thickness >= 250:\n",
    "                return 2.0\n",
    "            elif thickness >= 150:\n",
    "                return 1.5\n",
    "            elif thickness >= 75:\n",
    "                return 1.0\n",
    "            else:\n",
    "                return 0.5\n",
    "        \n",
    "        # Generic insulation mention\n",
    "        if \"insulat\" in t:\n",
    "            return 1.0\n",
    "        \n",
    "        return 0.0\n",
    "    \n",
    "    def score_walls_desc(self, txt: Any) -> float:\n",
    "        \"\"\"Score walls description (0-2 scale) with robust parsing.\"\"\"\n",
    "        if pd.isna(txt) or not isinstance(txt, str):\n",
    "            return 0.0\n",
    "        \n",
    "        t = txt.lower()\n",
    "        \n",
    "        # Check for negative mentions first\n",
    "        if self._has_negative_insulation(t):\n",
    "            return 0.0\n",
    "        \n",
    "        # Check for partial/limited insulation\n",
    "        if \"partial\" in t or \"limited\" in t:\n",
    "            return 0.5\n",
    "        \n",
    "        # Check for external/internal wall insulation\n",
    "        if any(k in t for k in [\"external insulation\", \"internal insulation\", \" ewi\", \" iwi\"]):\n",
    "            return 2.0\n",
    "        \n",
    "        # Check U-values (wall thresholds)\n",
    "        u_value = self._extract_uvalue(t)\n",
    "        if u_value is not None:\n",
    "            if u_value <= 0.18:\n",
    "                return 2.0  # Excellent\n",
    "            elif u_value <= 0.30:\n",
    "                return 1.5  # Good\n",
    "            elif u_value <= 0.45:\n",
    "                return 1.0  # Moderate\n",
    "            else:\n",
    "                return 0.0  # Too high\n",
    "        \n",
    "        # Check for cavity wall insulation\n",
    "        if \"cavity\" in t and (\"filled\" in t or \"insulat\" in t):\n",
    "            return 2.0\n",
    "        \n",
    "        # Check for solid wall with insulation\n",
    "        if \"solid\" in t and \"insulat\" in t:\n",
    "            return 2.0\n",
    "        \n",
    "        # Generic insulation mention\n",
    "        if \"insulat\" in t:\n",
    "            return 1.0\n",
    "        \n",
    "        # Cavity wall without insulation\n",
    "        if \"cavity\" in t and \"unfilled\" not in t:\n",
    "            return 0.3  # Has potential for improvement\n",
    "        \n",
    "        return 0.0\n",
    "    \n",
    "    def score_floor_desc(self, txt: Any) -> float:\n",
    "        \"\"\"Score floor description (0-1 scale) with robust parsing.\"\"\"\n",
    "        if pd.isna(txt) or not isinstance(txt, str):\n",
    "            return 0.0\n",
    "        \n",
    "        t = txt.lower()\n",
    "        \n",
    "        # Check for negative mentions first\n",
    "        if self._has_negative_insulation(t):\n",
    "            return 0.0\n",
    "        \n",
    "        # Check for partial/limited insulation\n",
    "        if \"partial\" in t or \"limited\" in t:\n",
    "            return 0.5\n",
    "        \n",
    "        # Check U-values (floor thresholds)\n",
    "        u_value = self._extract_uvalue(t)\n",
    "        if u_value is not None:\n",
    "            if u_value <= 0.18:\n",
    "                return 1.0  # Excellent\n",
    "            elif u_value <= 0.25:\n",
    "                return 0.8  # Good\n",
    "            elif u_value <= 0.45:\n",
    "                return 0.5  # Moderate\n",
    "            else:\n",
    "                return 0.0  # Too high\n",
    "        \n",
    "        # Check for insulation\n",
    "        if \"insulat\" in t:\n",
    "            return 1.0\n",
    "        \n",
    "        # Suspended timber floor (has upgrade potential)\n",
    "        if \"suspended\" in t and \"timber\" in t:\n",
    "            return 0.3\n",
    "        \n",
    "        return 0.0\n",
    "    \n",
    "    def add_desc_scores(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Add description scores for available categorical features.\"\"\"\n",
    "        df = df.copy()\n",
    "        \n",
    "        # Always add scores when columns exist (not dependent on importance)\n",
    "        if \"ROOF_DESCRIPTION\" in df.columns:\n",
    "            df[\"ROOF_DESC_SCORE\"] = df[\"ROOF_DESCRIPTION\"].apply(self.score_roof_desc)\n",
    "            self.logger.info(f\"  Added ROOF_DESC_SCORE (mean: {df['ROOF_DESC_SCORE'].mean():.2f})\")\n",
    "        \n",
    "        if \"WALLS_DESCRIPTION\" in df.columns:\n",
    "            df[\"WALLS_DESC_SCORE\"] = df[\"WALLS_DESCRIPTION\"].apply(self.score_walls_desc)\n",
    "            self.logger.info(f\"  Added WALLS_DESC_SCORE (mean: {df['WALLS_DESC_SCORE'].mean():.2f})\")\n",
    "        \n",
    "        if \"FLOOR_DESCRIPTION\" in df.columns:\n",
    "            df[\"FLOOR_DESC_SCORE\"] = df[\"FLOOR_DESCRIPTION\"].apply(self.score_floor_desc)\n",
    "            self.logger.info(f\"  Added FLOOR_DESC_SCORE (mean: {df['FLOOR_DESC_SCORE'].mean():.2f})\")\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def _convert_efficiency_to_numeric(self, series: pd.Series) -> pd.Series:\n",
    "        \"\"\"Convert efficiency ratings to numeric scale, treating Unknown/N/A as NaN.\"\"\"\n",
    "        mapping = {\n",
    "            \"Very Good\": 5,\n",
    "            \"Good\": 4,\n",
    "            \"Average\": 3,\n",
    "            \"Poor\": 2,\n",
    "            \"Very Poor\": 1,\n",
    "            \"N/A\": np.nan,\n",
    "            \"Unknown\": np.nan,\n",
    "            \"\": np.nan\n",
    "        }\n",
    "        \n",
    "        if series.dtype == 'object' or pd.api.types.is_categorical_dtype(series):\n",
    "            # Don't fill NaN with Average - keep as NaN\n",
    "            return series.map(mapping)\n",
    "        else:\n",
    "            return series\n",
    "    \n",
    "    def _numeric_to_efficiency(self, value: float) -> str:\n",
    "        \"\"\"Convert numeric efficiency back to categorical with proper clamping.\"\"\"\n",
    "        if pd.isna(value):\n",
    "            return \"Unknown\"\n",
    "        \n",
    "        # Ensure value is in valid range [1, 5]\n",
    "        value = np.clip(value, 1, 5)\n",
    "        \n",
    "        # Round to nearest integer for mapping\n",
    "        value = round(value)\n",
    "        \n",
    "        mapping = {\n",
    "            5: \"Very Good\",\n",
    "            4: \"Good\",\n",
    "            3: \"Average\",\n",
    "            2: \"Poor\",\n",
    "            1: \"Very Poor\"\n",
    "        }\n",
    "        \n",
    "        return mapping.get(value, \"Average\")\n",
    "    \n",
    "    def compute_upgrade_targets(self, epc_c_data: pd.DataFrame) -> Dict[int, Dict[str, Dict[str, float]]]:\n",
    "        \"\"\"Compute upgrade targets based on EPC C home characteristics.\"\"\"\n",
    "        # Add description scores first\n",
    "        epc_c_data = self.add_desc_scores(epc_c_data)\n",
    "        \n",
    "        targets = {}\n",
    "        clusters = sorted(epc_c_data['cluster'].unique())\n",
    "        \n",
    "        for cluster_id in clusters:\n",
    "            cluster_data = epc_c_data[epc_c_data['cluster'] == cluster_id].copy()\n",
    "            \n",
    "            targets[cluster_id] = {\n",
    "                'A0': {},  # Moderate upgrades\n",
    "                'A1': {}   # Ambitious upgrades\n",
    "            }\n",
    "            \n",
    "            # Process numeric fabric features (always include if available)\n",
    "            for feature in self.available_numeric_fabric:\n",
    "                numeric_vals = self._convert_efficiency_to_numeric(cluster_data[feature])\n",
    "                numeric_vals = numeric_vals.dropna()\n",
    "                \n",
    "                if len(numeric_vals) > 0:\n",
    "                    # Calculate percentiles and ensure valid range\n",
    "                    a0_val = np.percentile(numeric_vals, self.config.a0_percentile)\n",
    "                    a1_val = np.percentile(numeric_vals, self.config.a1_percentile)\n",
    "                    \n",
    "                    # Clamp to valid range [1, 5] and round\n",
    "                    targets[cluster_id]['A0'][feature] = np.clip(np.ceil(a0_val), 1, 5)\n",
    "                    targets[cluster_id]['A1'][feature] = np.clip(np.ceil(a1_val), 1, 5)\n",
    "            \n",
    "            # Process service features (always include if available)\n",
    "            for feature in self.available_service:\n",
    "                numeric_vals = self._convert_efficiency_to_numeric(cluster_data[feature])\n",
    "                numeric_vals = numeric_vals.dropna()\n",
    "                \n",
    "                if len(numeric_vals) > 0:\n",
    "                    a0_val = np.percentile(numeric_vals, self.config.a0_percentile)\n",
    "                    a1_val = np.percentile(numeric_vals, self.config.a1_percentile)\n",
    "                    \n",
    "                    targets[cluster_id]['A0'][feature] = np.clip(np.ceil(a0_val), 1, 5)\n",
    "                    targets[cluster_id]['A1'][feature] = np.clip(np.ceil(a1_val), 1, 5)\n",
    "            \n",
    "            # Process description scores\n",
    "            for score_col in ['ROOF_DESC_SCORE', 'WALLS_DESC_SCORE', 'FLOOR_DESC_SCORE']:\n",
    "                if score_col in cluster_data.columns:\n",
    "                    score_vals = cluster_data[score_col].dropna()\n",
    "                    if len(score_vals) > 0:\n",
    "                        targets[cluster_id]['A0'][score_col] = np.percentile(\n",
    "                            score_vals, self.config.a0_percentile\n",
    "                        )\n",
    "                        targets[cluster_id]['A1'][score_col] = np.percentile(\n",
    "                            score_vals, self.config.a1_percentile\n",
    "                        )\n",
    "            \n",
    "            # Process upgradeable numerical features\n",
    "            upgradeable_numerical = ['LOW_ENERGY_LIGHTING', 'PHOTO_SUPPLY']\n",
    "            for feature in upgradeable_numerical:\n",
    "                if feature in cluster_data.columns:\n",
    "                    numeric_vals = pd.to_numeric(cluster_data[feature], errors='coerce').dropna()\n",
    "                    if len(numeric_vals) > 0:\n",
    "                        targets[cluster_id]['A0'][feature] = np.percentile(\n",
    "                            numeric_vals, self.config.a0_percentile\n",
    "                        )\n",
    "                        targets[cluster_id]['A1'][feature] = np.percentile(\n",
    "                            numeric_vals, self.config.a1_percentile\n",
    "                        )\n",
    "        \n",
    "        # CRITICAL FIX: Ensure A1 >= A0 and apply sensible minimum targets\n",
    "        for cluster_id in targets:\n",
    "            for feature in targets[cluster_id]['A0']:\n",
    "                if feature in targets[cluster_id]['A1']:\n",
    "                    # A1 must be at least as good as A0\n",
    "                    targets[cluster_id]['A1'][feature] = max(\n",
    "                        targets[cluster_id]['A1'][feature],\n",
    "                        targets[cluster_id]['A0'][feature]\n",
    "                    )\n",
    "                    \n",
    "                    # Special fix for windows - never target \"Very Poor\" for C-rated homes\n",
    "                    if feature == 'WINDOWS_ENERGY_EFF':\n",
    "                        targets[cluster_id]['A0'][feature] = max(3, targets[cluster_id]['A0'][feature])  # At least Average\n",
    "                        targets[cluster_id]['A1'][feature] = max(4, targets[cluster_id]['A1'][feature])  # At least Good\n",
    "                    \n",
    "                    # Ensure fabric features target at least \"Average\" for A0, \"Good\" for A1\n",
    "                    if feature in ['WALLS_ENERGY_EFF', 'ROOF_ENERGY_EFF', 'FLOOR_ENERGY_EFF']:\n",
    "                        targets[cluster_id]['A0'][feature] = max(3, targets[cluster_id]['A0'][feature])\n",
    "                        targets[cluster_id]['A1'][feature] = max(4, targets[cluster_id]['A1'][feature])\n",
    "                    \n",
    "                    # Ensure heating/hot water target at least \"Average\" for A0, \"Good\" for A1\n",
    "                    if feature in ['MAINHEAT_ENERGY_EFF', 'HOT_WATER_ENERGY_EFF']:\n",
    "                        targets[cluster_id]['A0'][feature] = max(3, targets[cluster_id]['A0'][feature])\n",
    "                        targets[cluster_id]['A1'][feature] = max(4, targets[cluster_id]['A1'][feature])\n",
    "        \n",
    "        self.logger.info(f\"Computed upgrade targets for {len(targets)} clusters\")\n",
    "        self._log_target_summary(targets)\n",
    "        \n",
    "        return targets\n",
    "    \n",
    "    def _log_target_summary(self, targets: Dict) -> None:\n",
    "        \"\"\"Log summary of computed targets.\"\"\"\n",
    "        for cluster_id in targets:\n",
    "            self.logger.info(f\"\\nCluster {cluster_id} targets:\")\n",
    "            for scenario in ['A0', 'A1']:\n",
    "                self.logger.info(f\"  {scenario}:\")\n",
    "                for feature, value in targets[cluster_id][scenario].items():\n",
    "                    if feature in self.available_numeric_fabric + self.available_service:\n",
    "                        # Convert back to label for logging\n",
    "                        label = self._numeric_to_efficiency(value)\n",
    "                        self.logger.info(f\"    {feature}: {value} ({label})\")\n",
    "                    else:\n",
    "                        self.logger.info(f\"    {feature}: {value:.2f}\")\n",
    "    \n",
    "    def create_upgrade_scenarios(self, substandard_data: pd.DataFrame, \n",
    "                                targets: Dict) -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
    "        \"\"\"Create A0 and A1 upgrade scenarios for substandard homes.\"\"\"\n",
    "        # Add description scores to substandard data\n",
    "        substandard_data = self.add_desc_scores(substandard_data)\n",
    "        \n",
    "        # Create copies for scenarios\n",
    "        baseline_df = substandard_data.copy()\n",
    "        a0_df = substandard_data.copy()\n",
    "        a1_df = substandard_data.copy()\n",
    "        \n",
    "        # Track upgrades applied\n",
    "        a0_upgrades = []\n",
    "        a1_upgrades = []\n",
    "        \n",
    "        for idx in range(len(substandard_data)):\n",
    "            cluster_id = int(substandard_data.iloc[idx]['matched_cluster'])\n",
    "            \n",
    "            if cluster_id not in targets:\n",
    "                self.logger.warning(f\"No targets for cluster {cluster_id}\")\n",
    "                a0_upgrades.append({})\n",
    "                a1_upgrades.append({})\n",
    "                continue\n",
    "            \n",
    "            # CRITICAL FIX: Apply upgrades directly to DataFrame using .loc\n",
    "            # Apply A0 (moderate) upgrades\n",
    "            a0_home_upgrades = self._apply_upgrades_inplace(\n",
    "                a0_df, idx, targets[cluster_id]['A0'], 'A0'\n",
    "            )\n",
    "            a0_upgrades.append(a0_home_upgrades)\n",
    "            \n",
    "            # Apply A1 (ambitious) upgrades  \n",
    "            a1_home_upgrades = self._apply_upgrades_inplace(\n",
    "                a1_df, idx, targets[cluster_id]['A1'], 'A1'\n",
    "            )\n",
    "            a1_upgrades.append(a1_home_upgrades)\n",
    "        \n",
    "        # Add upgrade tracking columns\n",
    "        a0_df['upgrades_applied'] = a0_upgrades\n",
    "        a1_df['upgrades_applied'] = a1_upgrades\n",
    "        a0_df['scenario'] = 'A0_moderate'\n",
    "        a1_df['scenario'] = 'A1_ambitious'\n",
    "        baseline_df['scenario'] = 'baseline'\n",
    "        \n",
    "        # Log upgrade statistics\n",
    "        self._log_upgrade_statistics(a0_upgrades, a1_upgrades)\n",
    "        \n",
    "        return baseline_df, a0_df, a1_df\n",
    "    \n",
    "    def _apply_upgrades_inplace(self, df: pd.DataFrame, idx: int, targets: Dict[str, float], \n",
    "                                scenario: str) -> Dict[str, bool]:\n",
    "        \"\"\"Apply upgrades directly to DataFrame row (in-place modification).\"\"\"\n",
    "        upgrades = {}\n",
    "        \n",
    "        # Apply numeric fabric upgrades\n",
    "        for feature in self.available_numeric_fabric:\n",
    "            if feature in targets and feature in df.columns:\n",
    "                current_val = self._convert_efficiency_to_numeric(\n",
    "                    pd.Series([df.loc[idx, feature]])\n",
    "                ).iloc[0]\n",
    "                target_val = targets[feature]\n",
    "                \n",
    "                if not pd.isna(current_val) and not pd.isna(target_val):\n",
    "                    if target_val > current_val:\n",
    "                        # CRITICAL: Use .loc to modify in-place\n",
    "                        df.loc[idx, feature] = self._numeric_to_efficiency(target_val)\n",
    "                        upgrades[feature] = True\n",
    "                    else:\n",
    "                        upgrades[feature] = False\n",
    "        \n",
    "        # Apply service upgrades\n",
    "        for feature in self.available_service:\n",
    "            if feature in targets and feature in df.columns:\n",
    "                current_val = self._convert_efficiency_to_numeric(\n",
    "                    pd.Series([df.loc[idx, feature]])\n",
    "                ).iloc[0]\n",
    "                target_val = targets[feature]\n",
    "                \n",
    "                if not pd.isna(current_val) and not pd.isna(target_val):\n",
    "                    if target_val > current_val:\n",
    "                        df.loc[idx, feature] = self._numeric_to_efficiency(target_val)\n",
    "                        upgrades[feature] = True\n",
    "                    else:\n",
    "                        upgrades[feature] = False\n",
    "        \n",
    "        # FIX: When description scores improve, ALSO update the efficiency ratings\n",
    "        for score_col, desc_col, eff_col in [\n",
    "            ('ROOF_DESC_SCORE', 'ROOF_DESCRIPTION', 'ROOF_ENERGY_EFF'),\n",
    "            ('WALLS_DESC_SCORE', 'WALLS_DESCRIPTION', 'WALLS_ENERGY_EFF'),\n",
    "            ('FLOOR_DESC_SCORE', 'FLOOR_DESCRIPTION', 'FLOOR_ENERGY_EFF')\n",
    "        ]:\n",
    "            if score_col in targets and score_col in df.columns and eff_col in df.columns:\n",
    "                current_score = df.loc[idx, score_col] if score_col in df.columns else 0\n",
    "                target_score = targets[score_col]\n",
    "                \n",
    "                if not pd.isna(current_score) and not pd.isna(target_score):\n",
    "                    if target_score > current_score:\n",
    "                        # Update the score\n",
    "                        df.loc[idx, score_col] = target_score\n",
    "                        \n",
    "                        # CRITICAL: Also update the efficiency rating based on improved score\n",
    "                        current_eff = self._convert_efficiency_to_numeric(\n",
    "                            pd.Series([df.loc[idx, eff_col]])\n",
    "                        ).iloc[0] if eff_col in df.columns else 1\n",
    "                        \n",
    "                        # Map improved score to improved efficiency\n",
    "                        if scenario == 'A0' and target_score >= 1.0:\n",
    "                            new_eff = max(4, current_eff if not pd.isna(current_eff) else 3)  # At least \"Good\"\n",
    "                        elif scenario == 'A1' and target_score >= 1.5:\n",
    "                            new_eff = 5  # \"Very Good\" for ambitious\n",
    "                        else:\n",
    "                            new_eff = max(3, current_eff if not pd.isna(current_eff) else 2)  # At least \"Average\"\n",
    "                        \n",
    "                        df.loc[idx, eff_col] = self._numeric_to_efficiency(new_eff)\n",
    "                        upgrades[eff_col] = True\n",
    "        \n",
    "        # Apply numerical feature upgrades\n",
    "        for feature in ['LOW_ENERGY_LIGHTING', 'PHOTO_SUPPLY']:\n",
    "            if feature in targets and feature in df.columns:\n",
    "                current_val = pd.to_numeric(df.loc[idx, feature], errors='coerce')\n",
    "                target_val = targets[feature]\n",
    "                \n",
    "                if not pd.isna(current_val) and not pd.isna(target_val):\n",
    "                    if target_val > current_val:\n",
    "                        df.loc[idx, feature] = target_val\n",
    "                        upgrades[feature] = True\n",
    "        \n",
    "        return upgrades\n",
    "    \n",
    "    def _log_upgrade_statistics(self, a0_upgrades: List[Dict], a1_upgrades: List[Dict]):\n",
    "        \"\"\"Log statistics about upgrades applied.\"\"\"\n",
    "        self.logger.info(\"\\n\" + \"=\"*60)\n",
    "        self.logger.info(\"UPGRADE APPLICATION STATISTICS\")\n",
    "        self.logger.info(\"=\"*60)\n",
    "        \n",
    "        # Count upgrades by feature\n",
    "        a0_counts = {}\n",
    "        a1_counts = {}\n",
    "        \n",
    "        for upgrades in a0_upgrades:\n",
    "            for feature, upgraded in upgrades.items():\n",
    "                if upgraded:\n",
    "                    a0_counts[feature] = a0_counts.get(feature, 0) + 1\n",
    "        \n",
    "        for upgrades in a1_upgrades:\n",
    "            for feature, upgraded in upgrades.items():\n",
    "                if upgraded:\n",
    "                    a1_counts[feature] = a1_counts.get(feature, 0) + 1\n",
    "        \n",
    "        self.logger.info(\"\\nA0 (Moderate) upgrades applied:\")\n",
    "        for feature, count in sorted(a0_counts.items(), key=lambda x: x[1], reverse=True):\n",
    "            self.logger.info(f\"  {feature}: {count} homes ({count/len(a0_upgrades)*100:.1f}%)\")\n",
    "        \n",
    "        self.logger.info(\"\\nA1 (Ambitious) upgrades applied:\")\n",
    "        for feature, count in sorted(a1_counts.items(), key=lambda x: x[1], reverse=True):\n",
    "            self.logger.info(f\"  {feature}: {count} homes ({count/len(a1_upgrades)*100:.1f}%)\")\n",
    "        \n",
    "        # Check for differences between A0 and A1\n",
    "        all_features = set(a0_counts.keys()) | set(a1_counts.keys())\n",
    "        differences = []\n",
    "        for feature in all_features:\n",
    "            a0_count = a0_counts.get(feature, 0)\n",
    "            a1_count = a1_counts.get(feature, 0)\n",
    "            if a1_count > a0_count:\n",
    "                differences.append((feature, a1_count - a0_count))\n",
    "        \n",
    "        if differences:\n",
    "            self.logger.info(\"\\nAdditional upgrades in A1 vs A0:\")\n",
    "            for feature, diff in sorted(differences, key=lambda x: x[1], reverse=True):\n",
    "                self.logger.info(f\"  {feature}: +{diff} homes\")\n",
    "        else:\n",
    "            self.logger.warning(\"\\nWARNING: No difference between A0 and A1 upgrades!\")\n",
    "    \n",
    "    def predict_scenario_outcomes(self, baseline_df: pd.DataFrame, \n",
    "                                 a0_df: pd.DataFrame, \n",
    "                                 a1_df: pd.DataFrame) -> None:\n",
    "        \"\"\"Use H2O model to predict EPC ratings for each scenario.\"\"\"\n",
    "        self.logger.info(\"Predicting outcomes for scenarios...\")\n",
    "        \n",
    "        # Prepare features (exclude metadata columns)\n",
    "        exclude_cols = [\n",
    "            'CURRENT_ENERGY_RATING', 'cluster', 'matched_cluster',\n",
    "            'distance_to_centroid', 'upgrades_needed', 'upgrade_priority_score',\n",
    "            'upgrades_applied', 'scenario', 'ROOF_DESC_SCORE', 'WALLS_DESC_SCORE', \n",
    "            'FLOOR_DESC_SCORE'\n",
    "        ]\n",
    "        \n",
    "        feature_cols = [col for col in baseline_df.columns if col not in exclude_cols]\n",
    "        \n",
    "        # Create H2O frames\n",
    "        baseline_h2o = H2OFrame(baseline_df[feature_cols])\n",
    "        a0_h2o = H2OFrame(a0_df[feature_cols])\n",
    "        a1_h2o = H2OFrame(a1_df[feature_cols])\n",
    "        \n",
    "        # Ensure proper types\n",
    "        categorical_cols = (self.config.categorical_features + \n",
    "                          self.available_numeric_fabric + \n",
    "                          self.available_service)\n",
    "        \n",
    "        for col in feature_cols:\n",
    "            if col in categorical_cols:\n",
    "                baseline_h2o[col] = baseline_h2o[col].asfactor()\n",
    "                a0_h2o[col] = a0_h2o[col].asfactor()\n",
    "                a1_h2o[col] = a1_h2o[col].asfactor()\n",
    "        \n",
    "        # Make predictions\n",
    "        baseline_pred = self.h2o_model.predict(baseline_h2o)\n",
    "        a0_pred = self.h2o_model.predict(a0_h2o)\n",
    "        a1_pred = self.h2o_model.predict(a1_h2o)\n",
    "        \n",
    "        # Extract predictions - FIX: flatten the 2D array to 1D\n",
    "        baseline_df['predicted_rating'] = baseline_pred['predict'].as_data_frame().values.ravel()\n",
    "        a0_df['predicted_rating'] = a0_pred['predict'].as_data_frame().values.ravel()\n",
    "        a1_df['predicted_rating'] = a1_pred['predict'].as_data_frame().values.ravel()\n",
    "        \n",
    "        # Get probability of achieving C or better\n",
    "        baseline_pred_df = baseline_pred.as_data_frame()\n",
    "        a0_pred_df = a0_pred.as_data_frame()\n",
    "        a1_pred_df = a1_pred.as_data_frame()\n",
    "        \n",
    "        prob_cols = [col for col in baseline_pred_df.columns if col.startswith('p') or col in ['A','B','C','D','E','F','G']]\n",
    "        \n",
    "        if prob_cols:\n",
    "            # Determine which columns represent A, B, C\n",
    "            c_or_better_cols = []\n",
    "            \n",
    "            # Check for different possible naming conventions\n",
    "            if 'A' in prob_cols and 'B' in prob_cols and 'C' in prob_cols:\n",
    "                c_or_better_cols = ['A', 'B', 'C']\n",
    "            elif 'pA' in prob_cols and 'pB' in prob_cols and 'pC' in prob_cols:\n",
    "                c_or_better_cols = ['pA', 'pB', 'pC']\n",
    "            else:\n",
    "                # Try to identify based on column order\n",
    "                sorted_prob_cols = sorted([col for col in prob_cols if col != 'predict'])\n",
    "                if len(sorted_prob_cols) >= 7:  # Should have 7 classes (A-G)\n",
    "                    c_or_better_cols = sorted_prob_cols[:3]  # First three are A, B, C\n",
    "            \n",
    "            if c_or_better_cols:\n",
    "                # Calculate probability of C or better\n",
    "                baseline_df['prob_c_or_better'] = baseline_pred_df[c_or_better_cols].sum(axis=1).values\n",
    "                a0_df['prob_c_or_better'] = a0_pred_df[c_or_better_cols].sum(axis=1).values\n",
    "                a1_df['prob_c_or_better'] = a1_pred_df[c_or_better_cols].sum(axis=1).values\n",
    "            else:\n",
    "                self.logger.warning(\"Could not identify probability columns for ratings A, B, C\")\n",
    "                baseline_df['prob_c_or_better'] = np.nan\n",
    "                a0_df['prob_c_or_better'] = np.nan\n",
    "                a1_df['prob_c_or_better'] = np.nan\n",
    "        else:\n",
    "            self.logger.warning(\"No probability columns found in predictions\")\n",
    "            baseline_df['prob_c_or_better'] = np.nan\n",
    "            a0_df['prob_c_or_better'] = np.nan\n",
    "            a1_df['prob_c_or_better'] = np.nan\n",
    "        \n",
    "        # Calculate improvements\n",
    "        baseline_df['rating_improvement'] = 0\n",
    "        a0_df['rating_improvement'] = self._calculate_rating_improvement(\n",
    "            baseline_df['CURRENT_ENERGY_RATING'], \n",
    "            a0_df['predicted_rating']\n",
    "        )\n",
    "        a1_df['rating_improvement'] = self._calculate_rating_improvement(\n",
    "            baseline_df['CURRENT_ENERGY_RATING'], \n",
    "            a1_df['predicted_rating']\n",
    "        )\n",
    "        \n",
    "        # Store results\n",
    "        self.baseline_df = baseline_df\n",
    "        self.a0_scenario_df = a0_df\n",
    "        self.a1_scenario_df = a1_df\n",
    "        \n",
    "        self.logger.info(\"Scenario predictions completed\")\n",
    "        self._log_prediction_summary()\n",
    "    \n",
    "    def _calculate_rating_improvement(self, current: pd.Series, predicted: pd.Series) -> pd.Series:\n",
    "        \"\"\"Calculate the number of rating bands improved.\"\"\"\n",
    "        rating_map = {'A': 7, 'B': 6, 'C': 5, 'D': 4, 'E': 3, 'F': 2, 'G': 1}\n",
    "        \n",
    "        current_numeric = current.map(rating_map)\n",
    "        predicted_numeric = predicted.astype(str).map(rating_map)\n",
    "        \n",
    "        return predicted_numeric - current_numeric\n",
    "    \n",
    "    def _log_prediction_summary(self) -> None:\n",
    "        \"\"\"Log summary of prediction outcomes.\"\"\"\n",
    "        self.logger.info(\"\\n\" + \"=\"*60)\n",
    "        self.logger.info(\"PREDICTION SUMMARY\")\n",
    "        self.logger.info(\"=\"*60)\n",
    "        \n",
    "        # A0 Scenario outcomes\n",
    "        self.logger.info(\"\\nA0 (Moderate) Scenario:\")\n",
    "        a0_improved = (self.a0_scenario_df['rating_improvement'] > 0).sum()\n",
    "        a0_achieved_c = (self.a0_scenario_df['predicted_rating'].isin(['A', 'B', 'C'])).sum()\n",
    "        self.logger.info(f\"  Homes improved: {a0_improved}/{len(self.a0_scenario_df)} \"\n",
    "                        f\"({a0_improved/len(self.a0_scenario_df)*100:.1f}%)\")\n",
    "        self.logger.info(f\"  Achieved C or better: {a0_achieved_c}/{len(self.a0_scenario_df)} \"\n",
    "                        f\"({a0_achieved_c/len(self.a0_scenario_df)*100:.1f}%)\")\n",
    "        self.logger.info(f\"  Mean improvement: {self.a0_scenario_df['rating_improvement'].mean():.2f} bands\")\n",
    "        \n",
    "        # A1 Scenario outcomes\n",
    "        self.logger.info(\"\\nA1 (Ambitious) Scenario:\")\n",
    "        a1_improved = (self.a1_scenario_df['rating_improvement'] > 0).sum()\n",
    "        a1_achieved_c = (self.a1_scenario_df['predicted_rating'].isin(['A', 'B', 'C'])).sum()\n",
    "        self.logger.info(f\"  Homes improved: {a1_improved}/{len(self.a1_scenario_df)} \"\n",
    "                        f\"({a1_improved/len(self.a1_scenario_df)*100:.1f}%)\")\n",
    "        self.logger.info(f\"  Achieved C or better: {a1_achieved_c}/{len(self.a1_scenario_df)} \"\n",
    "                        f\"({a1_achieved_c/len(self.a1_scenario_df)*100:.1f}%)\")\n",
    "        self.logger.info(f\"  Mean improvement: {self.a1_scenario_df['rating_improvement'].mean():.2f} bands\")\n",
    "        \n",
    "        # Check if A0 and A1 are different\n",
    "        if a0_improved == a1_improved and a0_achieved_c == a1_achieved_c:\n",
    "            self.logger.warning(\"\\nWARNING: A0 and A1 scenarios show identical outcomes!\")\n",
    "            self.logger.warning(\"This suggests upgrades may not be properly differentiating.\")\n",
    "    \n",
    "    def calculate_costs_and_benefits(self) -> pd.DataFrame:\n",
    "        \"\"\"Calculate upgrade costs and energy savings for each scenario.\"\"\"\n",
    "        self.logger.info(\"Calculating costs and benefits...\")\n",
    "        \n",
    "        results = []\n",
    "        \n",
    "        for idx in range(len(self.baseline_df)):\n",
    "            baseline_row = self.baseline_df.iloc[idx]\n",
    "            a0_row = self.a0_scenario_df.iloc[idx]\n",
    "            a1_row = self.a1_scenario_df.iloc[idx]\n",
    "            \n",
    "            # Calculate costs with fixed glazing proportion\n",
    "            a0_cost = self._calculate_upgrade_cost(\n",
    "                baseline_row, a0_row, a0_row['upgrades_applied']\n",
    "            )\n",
    "            a1_cost = self._calculate_upgrade_cost(\n",
    "                baseline_row, a1_row, a1_row['upgrades_applied']\n",
    "            )\n",
    "            \n",
    "            # Estimate energy savings\n",
    "            a0_savings = self._estimate_energy_savings(\n",
    "                baseline_row['CURRENT_ENERGY_RATING'],\n",
    "                a0_row['predicted_rating'],\n",
    "                pd.to_numeric(baseline_row.get('TOTAL_FLOOR_AREA', 90), errors='coerce')\n",
    "            )\n",
    "            a1_savings = self._estimate_energy_savings(\n",
    "                baseline_row['CURRENT_ENERGY_RATING'],\n",
    "                a1_row['predicted_rating'],\n",
    "                pd.to_numeric(baseline_row.get('TOTAL_FLOOR_AREA', 90), errors='coerce')\n",
    "            )\n",
    "            \n",
    "            # Calculate payback periods\n",
    "            a0_payback = a0_cost / a0_savings if a0_savings > 0 else np.inf\n",
    "            a1_payback = a1_cost / a1_savings if a1_savings > 0 else np.inf\n",
    "            \n",
    "            results.append({\n",
    "                'property_id': idx,\n",
    "                'current_rating': baseline_row['CURRENT_ENERGY_RATING'],\n",
    "                'cluster': baseline_row['matched_cluster'],\n",
    "                \n",
    "                'a0_predicted_rating': a0_row['predicted_rating'],\n",
    "                'a0_improvement': a0_row['rating_improvement'],\n",
    "                'a0_cost': a0_cost,\n",
    "                'a0_annual_savings': a0_savings,\n",
    "                'a0_payback_years': a0_payback,\n",
    "                'a0_prob_c_or_better': a0_row.get('prob_c_or_better', np.nan),\n",
    "                \n",
    "                'a1_predicted_rating': a1_row['predicted_rating'],\n",
    "                'a1_improvement': a1_row['rating_improvement'],\n",
    "                'a1_cost': a1_cost,\n",
    "                'a1_annual_savings': a1_savings,\n",
    "                'a1_payback_years': a1_payback,\n",
    "                'a1_prob_c_or_better': a1_row.get('prob_c_or_better', np.nan),\n",
    "                \n",
    "                'cost_per_improvement_a0': a0_cost / max(a0_row['rating_improvement'], 1),\n",
    "                'cost_per_improvement_a1': a1_cost / max(a1_row['rating_improvement'], 1),\n",
    "            })\n",
    "        \n",
    "        self.cost_benefit_df = pd.DataFrame(results)\n",
    "        self._log_cost_benefit_summary()\n",
    "        \n",
    "        return self.cost_benefit_df\n",
    "    \n",
    "    def _calculate_upgrade_cost(self, baseline: pd.Series, upgraded: pd.Series, \n",
    "                               upgrades: Dict) -> float:\n",
    "        \"\"\"Calculate the cost of upgrades for a single home with FIXED scaling issues.\"\"\"\n",
    "        total_cost = 0.0\n",
    "        \n",
    "        # Get floor area and validate\n",
    "        floor_area = pd.to_numeric(baseline.get('TOTAL_FLOOR_AREA', 90), errors='coerce')\n",
    "        if pd.isna(floor_area) or floor_area <= 0:\n",
    "            floor_area = 90  # UK average\n",
    "        \n",
    "        # Cap floor area to reasonable range (20-500 sqm)\n",
    "        floor_area = np.clip(floor_area, 20, 500)\n",
    "        \n",
    "        # Estimate areas\n",
    "        wall_area = floor_area * 2.5  # Typical wall/floor ratio\n",
    "        \n",
    "        # CRITICAL FIX: Handle MULTI_GLAZE_PROPORTION correctly\n",
    "        glazing_ratio = pd.to_numeric(baseline.get('MULTI_GLAZE_PROPORTION', 15), errors='coerce')\n",
    "        \n",
    "        # If it's stored as percentage (0-100), convert to ratio (0-1)\n",
    "        if pd.notna(glazing_ratio) and glazing_ratio > 1:\n",
    "            glazing_ratio = glazing_ratio / 100.0\n",
    "        \n",
    "        # Ensure reasonable bounds (5-40% of wall area)\n",
    "        glazing_ratio = float(np.clip(glazing_ratio if pd.notna(glazing_ratio) else 0.15, 0.05, 0.40))\n",
    "        glazing_area = wall_area * glazing_ratio\n",
    "        \n",
    "        if isinstance(upgrades, dict):\n",
    "            # Wall insulation - only charge if efficiency actually changed\n",
    "            if upgrades.get('WALLS_ENERGY_EFF', False):\n",
    "                wall_desc = str(baseline.get('WALLS_DESCRIPTION', '')).lower()\n",
    "                if 'cavity' in wall_desc:\n",
    "                    total_cost += wall_area * self.config.costs['wall_insulation_cavity']\n",
    "                else:\n",
    "                    total_cost += wall_area * self.config.costs['wall_insulation_solid']\n",
    "            \n",
    "            # Roof insulation\n",
    "            if upgrades.get('ROOF_ENERGY_EFF', False):\n",
    "                roof_area = floor_area * 0.9  # Approximate roof area\n",
    "                total_cost += roof_area * self.config.costs['roof_insulation']\n",
    "            \n",
    "            # Floor insulation\n",
    "            if upgrades.get('FLOOR_ENERGY_EFF', False):\n",
    "                total_cost += floor_area * self.config.costs['floor_insulation']\n",
    "            \n",
    "            # Windows\n",
    "            if upgrades.get('WINDOWS_ENERGY_EFF', False):\n",
    "                total_cost += glazing_area * self.config.costs['double_glazing']\n",
    "            \n",
    "            # Heating system\n",
    "            if upgrades.get('MAINHEAT_ENERGY_EFF', False):\n",
    "                total_cost += self.config.costs['heating_system_upgrade']\n",
    "            \n",
    "            # Hot water system\n",
    "            if upgrades.get('HOT_WATER_ENERGY_EFF', False):\n",
    "                total_cost += self.config.costs['hot_water_upgrade']\n",
    "            \n",
    "            # Lighting\n",
    "            if upgrades.get('LIGHTING_ENERGY_EFF', False) or upgrades.get('LOW_ENERGY_LIGHTING', False):\n",
    "                total_cost += self.config.costs['lighting_upgrade']\n",
    "        \n",
    "        return total_cost\n",
    "    \n",
    "    def _estimate_energy_savings(self, current_rating: str, predicted_rating: str, \n",
    "                                floor_area: float = 90) -> float:\n",
    "        \"\"\"Estimate annual energy cost savings from rating improvement with size scaling.\"\"\"\n",
    "        # Base consumption by rating (for 90 sqm reference home)\n",
    "        consumption_by_rating = {\n",
    "            'A': 8000,   # kWh/year\n",
    "            'B': 12000,\n",
    "            'C': 16000,\n",
    "            'D': 20000,\n",
    "            'E': 24000,\n",
    "            'F': 28000,\n",
    "            'G': 32000\n",
    "        }\n",
    "        \n",
    "        # Scale by floor area\n",
    "        if pd.isna(floor_area) or floor_area <= 0:\n",
    "            floor_area = 90\n",
    "        size_factor = np.clip((floor_area / 90.0), 0.5, 2.0)  # 90 m² reference\n",
    "        \n",
    "        current_consumption = consumption_by_rating.get(current_rating, 25000) * size_factor\n",
    "        predicted_consumption = consumption_by_rating.get(predicted_rating, current_consumption) * size_factor\n",
    "        \n",
    "        kwh_saved = current_consumption - predicted_consumption\n",
    "        annual_savings = kwh_saved * self.config.energy_price_per_kwh\n",
    "        \n",
    "        return max(0, annual_savings)\n",
    "    \n",
    "    def _log_cost_benefit_summary(self) -> None:\n",
    "        \"\"\"Log summary of cost-benefit analysis.\"\"\"\n",
    "        self.logger.info(\"\\n\" + \"=\"*60)\n",
    "        self.logger.info(\"COST-BENEFIT SUMMARY\")\n",
    "        self.logger.info(\"=\"*60)\n",
    "        \n",
    "        # A0 Scenario\n",
    "        self.logger.info(\"\\nA0 (Moderate) Scenario:\")\n",
    "        self.logger.info(f\"  Average cost: £{self.cost_benefit_df['a0_cost'].mean():,.2f}\")\n",
    "        self.logger.info(f\"  Median cost: £{self.cost_benefit_df['a0_cost'].median():,.2f}\")\n",
    "        self.logger.info(f\"  Average annual savings: £{self.cost_benefit_df['a0_annual_savings'].mean():,.2f}\")\n",
    "        \n",
    "        payback_finite = self.cost_benefit_df[self.cost_benefit_df['a0_payback_years'] < 50]['a0_payback_years']\n",
    "        if len(payback_finite) > 0:\n",
    "            self.logger.info(f\"  Average payback period: {payback_finite.mean():.1f} years\")\n",
    "            self.logger.info(f\"  Median payback period: {payback_finite.median():.1f} years\")\n",
    "        \n",
    "        self.logger.info(f\"  Cost per rating improvement: £{self.cost_benefit_df['cost_per_improvement_a0'].mean():,.2f}\")\n",
    "        \n",
    "        # A1 Scenario\n",
    "        self.logger.info(\"\\nA1 (Ambitious) Scenario:\")\n",
    "        self.logger.info(f\"  Average cost: £{self.cost_benefit_df['a1_cost'].mean():,.2f}\")\n",
    "        self.logger.info(f\"  Median cost: £{self.cost_benefit_df['a1_cost'].median():,.2f}\")\n",
    "        self.logger.info(f\"  Average annual savings: £{self.cost_benefit_df['a1_annual_savings'].mean():,.2f}\")\n",
    "        \n",
    "        payback_finite = self.cost_benefit_df[self.cost_benefit_df['a1_payback_years'] < 50]['a1_payback_years']\n",
    "        if len(payback_finite) > 0:\n",
    "            self.logger.info(f\"  Average payback period: {payback_finite.mean():.1f} years\")\n",
    "            self.logger.info(f\"  Median payback period: {payback_finite.median():.1f} years\")\n",
    "        \n",
    "        self.logger.info(f\"  Cost per rating improvement: £{self.cost_benefit_df['cost_per_improvement_a1'].mean():,.2f}\")\n",
    "        \n",
    "        # Check for reasonable values\n",
    "        if self.cost_benefit_df['a0_cost'].mean() > 100000:\n",
    "            self.logger.warning(\"\\nWARNING: Average costs still seem too high! Check floor area and glazing data.\")\n",
    "        \n",
    "        if abs(self.cost_benefit_df['a0_cost'].mean() - self.cost_benefit_df['a1_cost'].mean()) < 100:\n",
    "            self.logger.warning(\"\\nWARNING: A0 and A1 costs are nearly identical! Check upgrade differentiation.\")\n",
    "    \n",
    "    def calculate_cost_by_rating_band(self) -> pd.DataFrame:\n",
    "        \"\"\"Calculate average upgrade costs by initial rating band.\"\"\"\n",
    "        self.logger.info(\"Calculating average costs by rating band...\")\n",
    "        \n",
    "        # Initialize results dictionary\n",
    "        rating_analysis = {\n",
    "            'rating': [],\n",
    "            'total_homes': [],\n",
    "            'a0_avg_cost': [],\n",
    "            'a0_success_rate': [],\n",
    "            'a0_avg_cost_per_success': [],\n",
    "            'a1_avg_cost': [],\n",
    "            'a1_success_rate': [],\n",
    "            'a1_avg_cost_per_success': [],\n",
    "        }\n",
    "        \n",
    "        # Analyze each sub-standard rating\n",
    "        for rating in ['D', 'E', 'F', 'G']:\n",
    "            # Filter homes with this rating\n",
    "            mask = self.cost_benefit_df['current_rating'] == rating\n",
    "            rating_homes = self.cost_benefit_df[mask]\n",
    "            \n",
    "            if len(rating_homes) == 0:\n",
    "                continue\n",
    "                \n",
    "            # Calculate A0 metrics\n",
    "            a0_success = rating_homes['a0_predicted_rating'].isin(['A', 'B', 'C'])\n",
    "            a0_success_rate = a0_success.mean()\n",
    "            a0_avg_cost = rating_homes['a0_cost'].mean()\n",
    "            \n",
    "            # Cost per successful upgrade (only for homes that reached C or better)\n",
    "            if a0_success.sum() > 0:\n",
    "                a0_cost_per_success = rating_homes[a0_success]['a0_cost'].mean()\n",
    "            else:\n",
    "                a0_cost_per_success = np.nan\n",
    "                \n",
    "            # Calculate A1 metrics  \n",
    "            a1_success = rating_homes['a1_predicted_rating'].isin(['A', 'B', 'C'])\n",
    "            a1_success_rate = a1_success.mean()\n",
    "            a1_avg_cost = rating_homes['a1_cost'].mean()\n",
    "            \n",
    "            # Cost per successful upgrade\n",
    "            if a1_success.sum() > 0:\n",
    "                a1_cost_per_success = rating_homes[a1_success]['a1_cost'].mean()\n",
    "            else:\n",
    "                a1_cost_per_success = np.nan\n",
    "                \n",
    "            # Store results\n",
    "            rating_analysis['rating'].append(rating)\n",
    "            rating_analysis['total_homes'].append(len(rating_homes))\n",
    "            rating_analysis['a0_avg_cost'].append(a0_avg_cost)\n",
    "            rating_analysis['a0_success_rate'].append(a0_success_rate)\n",
    "            rating_analysis['a0_avg_cost_per_success'].append(a0_cost_per_success)\n",
    "            rating_analysis['a1_avg_cost'].append(a1_avg_cost)\n",
    "            rating_analysis['a1_success_rate'].append(a1_success_rate)\n",
    "            rating_analysis['a1_avg_cost_per_success'].append(a1_cost_per_success)\n",
    "        \n",
    "        # Create DataFrame\n",
    "        rating_cost_df = pd.DataFrame(rating_analysis)\n",
    "        \n",
    "        # Add difficulty metrics (how much harder/costlier for worse ratings)\n",
    "        if len(rating_cost_df) > 0:\n",
    "            # Use D as baseline\n",
    "            d_idx = rating_cost_df[rating_cost_df['rating'] == 'D'].index\n",
    "            if len(d_idx) > 0:\n",
    "                d_idx = d_idx[0]\n",
    "                d_a0_cost = rating_cost_df.loc[d_idx, 'a0_avg_cost']\n",
    "                d_a1_cost = rating_cost_df.loc[d_idx, 'a1_avg_cost']\n",
    "                \n",
    "                rating_cost_df['a0_cost_ratio_to_D'] = rating_cost_df['a0_avg_cost'] / d_a0_cost\n",
    "                rating_cost_df['a1_cost_ratio_to_D'] = rating_cost_df['a1_avg_cost'] / d_a1_cost\n",
    "        \n",
    "        # Log the analysis\n",
    "        self._log_rating_band_analysis(rating_cost_df)\n",
    "        \n",
    "        # Save to results\n",
    "        rating_cost_df.to_csv(\n",
    "            self.results_dir / f'cost_by_rating_band_{self.run_timestamp}.csv',\n",
    "            index=False\n",
    "        )\n",
    "        \n",
    "        self.rating_cost_df = rating_cost_df\n",
    "        return rating_cost_df\n",
    "    \n",
    "    def _log_rating_band_analysis(self, df: pd.DataFrame) -> None:\n",
    "        \"\"\"Log the rating band cost analysis.\"\"\"\n",
    "        self.logger.info(\"\\n\" + \"=\"*60)\n",
    "        self.logger.info(\"COST ANALYSIS BY INITIAL RATING\")\n",
    "        self.logger.info(\"=\"*60)\n",
    "        \n",
    "        for _, row in df.iterrows():\n",
    "            self.logger.info(f\"\\nRating {row['rating']} → C:\")\n",
    "            self.logger.info(f\"  Total homes: {int(row['total_homes'])}\")\n",
    "            \n",
    "            self.logger.info(f\"  A0 (Moderate):\")\n",
    "            self.logger.info(f\"    Average cost: £{row['a0_avg_cost']:,.2f}\")\n",
    "            self.logger.info(f\"    Success rate: {row['a0_success_rate']*100:.1f}%\")\n",
    "            if not pd.isna(row['a0_avg_cost_per_success']):\n",
    "                self.logger.info(f\"    Cost per success: £{row['a0_avg_cost_per_success']:,.2f}\")\n",
    "            \n",
    "            self.logger.info(f\"  A1 (Ambitious):\")\n",
    "            self.logger.info(f\"    Average cost: £{row['a1_avg_cost']:,.2f}\")\n",
    "            self.logger.info(f\"    Success rate: {row['a1_success_rate']*100:.1f}%\")\n",
    "            if not pd.isna(row['a1_avg_cost_per_success']):\n",
    "                self.logger.info(f\"    Cost per success: £{row['a1_avg_cost_per_success']:,.2f}\")\n",
    "        \n",
    "        # Summary insights\n",
    "        self.logger.info(\"\\nKEY INSIGHTS:\")\n",
    "        \n",
    "        # Cost progression\n",
    "        if 'a0_cost_ratio_to_D' in df.columns:\n",
    "            self.logger.info(\"\\nCost multipliers relative to D→C upgrade:\")\n",
    "            for _, row in df.iterrows():\n",
    "                if row['rating'] != 'D' and not pd.isna(row.get('a0_cost_ratio_to_D')):\n",
    "                    self.logger.info(f\"  {row['rating']}→C costs {row['a0_cost_ratio_to_D']:.1f}x \"\n",
    "                                   f\"more than D→C (A0)\")\n",
    "        \n",
    "        # Most cost-effective starting point\n",
    "        if len(df) > 0:\n",
    "            best_value_a0_idx = df['a0_avg_cost_per_success'].idxmin()\n",
    "            best_value_a1_idx = df['a1_avg_cost_per_success'].idxmin()\n",
    "            \n",
    "            if pd.notna(best_value_a0_idx):\n",
    "                best_value_a0 = df.loc[best_value_a0_idx]\n",
    "                self.logger.info(f\"\\nMost cost-effective upgrades:\")\n",
    "                self.logger.info(f\"  A0: {best_value_a0['rating']}→C \"\n",
    "                                f\"(£{best_value_a0['a0_avg_cost_per_success']:,.0f} per success)\")\n",
    "            \n",
    "            if pd.notna(best_value_a1_idx):\n",
    "                best_value_a1 = df.loc[best_value_a1_idx]\n",
    "                self.logger.info(f\"  A1: {best_value_a1['rating']}→C \"\n",
    "                                f\"(£{best_value_a1['a1_avg_cost_per_success']:,.0f} per success)\")\n",
    "    \n",
    "    def visualize_cost_by_rating(self, rating_cost_df: pd.DataFrame) -> None:\n",
    "        \"\"\"Create visualization of costs by initial rating band.\"\"\"\n",
    "        import matplotlib.pyplot as plt\n",
    "        import seaborn as sns\n",
    "        \n",
    "        fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "        \n",
    "        # Sort by rating order\n",
    "        rating_order = ['D', 'E', 'F', 'G']\n",
    "        rating_cost_df = rating_cost_df.set_index('rating').reindex(rating_order).reset_index()\n",
    "        \n",
    "        # 1. Average costs comparison\n",
    "        ax = axes[0, 0]\n",
    "        x = np.arange(len(rating_cost_df))\n",
    "        width = 0.35\n",
    "        \n",
    "        ax.bar(x - width/2, rating_cost_df['a0_avg_cost'], width, \n",
    "               label='A0 (Moderate)', color='steelblue', alpha=0.8)\n",
    "        ax.bar(x + width/2, rating_cost_df['a1_avg_cost'], width,\n",
    "               label='A1 (Ambitious)', color='coral', alpha=0.8)\n",
    "        \n",
    "        ax.set_xlabel('Initial Rating')\n",
    "        ax.set_ylabel('Average Upgrade Cost (£)')\n",
    "        ax.set_title('Average Cost to Achieve C by Initial Rating')\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels(rating_cost_df['rating'])\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        # Add value labels on bars\n",
    "        for i, (a0, a1) in enumerate(zip(rating_cost_df['a0_avg_cost'], \n",
    "                                         rating_cost_df['a1_avg_cost'])):\n",
    "            ax.text(i - width/2, a0 + 500, f'£{a0:,.0f}', ha='center', va='bottom', fontsize=9)\n",
    "            ax.text(i + width/2, a1 + 500, f'£{a1:,.0f}', ha='center', va='bottom', fontsize=9)\n",
    "        \n",
    "        # 2. Success rates\n",
    "        ax = axes[0, 1]\n",
    "        ax.bar(x - width/2, rating_cost_df['a0_success_rate'] * 100, width,\n",
    "               label='A0 (Moderate)', color='steelblue', alpha=0.8)\n",
    "        ax.bar(x + width/2, rating_cost_df['a1_success_rate'] * 100, width,\n",
    "               label='A1 (Ambitious)', color='coral', alpha=0.8)\n",
    "        \n",
    "        ax.set_xlabel('Initial Rating')\n",
    "        ax.set_ylabel('Success Rate (%)')\n",
    "        ax.set_title('Success Rate in Achieving C or Better')\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels(rating_cost_df['rating'])\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3, axis='y')\n",
    "        ax.set_ylim(0, 105)\n",
    "        \n",
    "        # 3. Cost per successful upgrade\n",
    "        ax = axes[1, 0]\n",
    "        ax.bar(x - width/2, rating_cost_df['a0_avg_cost_per_success'], width,\n",
    "               label='A0 (Moderate)', color='steelblue', alpha=0.8)\n",
    "        ax.bar(x + width/2, rating_cost_df['a1_avg_cost_per_success'], width,\n",
    "               label='A1 (Ambitious)', color='coral', alpha=0.8)\n",
    "        \n",
    "        ax.set_xlabel('Initial Rating')\n",
    "        ax.set_ylabel('Cost per Successful Upgrade (£)')\n",
    "        ax.set_title('Cost Efficiency: £ per Home Successfully Upgraded to C')\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels(rating_cost_df['rating'])\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        # 4. Number of homes per rating\n",
    "        ax = axes[1, 1]\n",
    "        colors = ['#2E7D32', '#558B2F', '#827717', '#BF360C']  # Green to red gradient\n",
    "        bars = ax.bar(rating_cost_df['rating'], rating_cost_df['total_homes'], \n",
    "                      color=colors, alpha=0.8)\n",
    "        \n",
    "        ax.set_xlabel('Initial Rating')\n",
    "        ax.set_ylabel('Number of Homes')\n",
    "        ax.set_title('Distribution of Homes by Initial Rating')\n",
    "        ax.grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        # Add percentage labels\n",
    "        total = rating_cost_df['total_homes'].sum()\n",
    "        for bar, count in zip(bars, rating_cost_df['total_homes']):\n",
    "            height = bar.get_height()\n",
    "            ax.text(bar.get_x() + bar.get_width()/2., height + 5,\n",
    "                    f'{count}\\n({count/total*100:.1f}%)',\n",
    "                    ha='center', va='bottom')\n",
    "        \n",
    "        plt.suptitle('Upgrade Cost Analysis by Initial EPC Rating', fontsize=14, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.plots_dir / 'cost_analysis_by_rating.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        self.logger.info(\"Rating band cost visualization saved\")\n",
    "    \n",
    "    def generate_visualizations(self) -> None:\n",
    "        \"\"\"Generate comprehensive visualizations of results.\"\"\"\n",
    "        import matplotlib.pyplot as plt\n",
    "        import seaborn as sns\n",
    "        \n",
    "        plt.style.use('default')\n",
    "        sns.set_palette(\"husl\")\n",
    "        \n",
    "        # 1. Rating improvement distribution\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "        \n",
    "        # A0 improvements\n",
    "        improvement_counts = self.a0_scenario_df['rating_improvement'].value_counts().sort_index()\n",
    "        ax1.bar(improvement_counts.index, improvement_counts.values, alpha=0.8, color='steelblue')\n",
    "        ax1.set_xlabel('Rating Bands Improved')\n",
    "        ax1.set_ylabel('Number of Homes')\n",
    "        ax1.set_title('A0 (Moderate) - Rating Improvements')\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        \n",
    "        # A1 improvements\n",
    "        improvement_counts = self.a1_scenario_df['rating_improvement'].value_counts().sort_index()\n",
    "        ax2.bar(improvement_counts.index, improvement_counts.values, alpha=0.8, color='coral')\n",
    "        ax2.set_xlabel('Rating Bands Improved')\n",
    "        ax2.set_ylabel('Number of Homes')\n",
    "        ax2.set_title('A1 (Ambitious) - Rating Improvements')\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.plots_dir / 'rating_improvements.png', dpi=300)\n",
    "        plt.close()\n",
    "        \n",
    "        # 2. Cost vs Benefit scatter (with reasonable cost bounds)\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "        \n",
    "        # Filter for reasonable costs (under £100k) and payback (under 50 years)\n",
    "        mask_a0 = (self.cost_benefit_df['a0_cost'] < 100000) & (self.cost_benefit_df['a0_payback_years'] < 50)\n",
    "        mask_a1 = (self.cost_benefit_df['a1_cost'] < 100000) & (self.cost_benefit_df['a1_payback_years'] < 50)\n",
    "        \n",
    "        # A0 cost-benefit\n",
    "        if mask_a0.sum() > 0:\n",
    "            ax1.scatter(self.cost_benefit_df[mask_a0]['a0_cost'], \n",
    "                       self.cost_benefit_df[mask_a0]['a0_annual_savings'],\n",
    "                       alpha=0.6, s=20, color='steelblue')\n",
    "            ax1.set_xlabel('Upgrade Cost (£)')\n",
    "            ax1.set_ylabel('Annual Savings (£)')\n",
    "            ax1.set_title('A0 - Cost vs Annual Savings')\n",
    "            ax1.grid(True, alpha=0.3)\n",
    "            \n",
    "            # Add payback lines\n",
    "            x_max = self.cost_benefit_df[mask_a0]['a0_cost'].max()\n",
    "            for years in [5, 10, 20]:\n",
    "                x = np.linspace(0, x_max, 100)\n",
    "                y = x / years\n",
    "                ax1.plot(x, y, '--', alpha=0.5, label=f'{years}yr payback')\n",
    "            ax1.legend()\n",
    "        \n",
    "        # A1 cost-benefit\n",
    "        if mask_a1.sum() > 0:\n",
    "            ax2.scatter(self.cost_benefit_df[mask_a1]['a1_cost'], \n",
    "                       self.cost_benefit_df[mask_a1]['a1_annual_savings'],\n",
    "                       alpha=0.6, s=20, color='coral')\n",
    "            ax2.set_xlabel('Upgrade Cost (£)')\n",
    "            ax2.set_ylabel('Annual Savings (£)')\n",
    "            ax2.set_title('A1 - Cost vs Annual Savings')\n",
    "            ax2.grid(True, alpha=0.3)\n",
    "            \n",
    "            # Add payback lines\n",
    "            x_max = self.cost_benefit_df[mask_a1]['a1_cost'].max()\n",
    "            for years in [5, 10, 20]:\n",
    "                x = np.linspace(0, x_max, 100)\n",
    "                y = x / years\n",
    "                ax2.plot(x, y, '--', alpha=0.5, label=f'{years}yr payback')\n",
    "            ax2.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.plots_dir / 'cost_benefit_analysis.png', dpi=300)\n",
    "        plt.close()\n",
    "        \n",
    "        # 3. Achievement rates by cluster\n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        \n",
    "        clusters = sorted(self.cost_benefit_df['cluster'].unique())\n",
    "        a0_rates = []\n",
    "        a1_rates = []\n",
    "        \n",
    "        for cluster in clusters:\n",
    "            mask = self.cost_benefit_df['cluster'] == cluster\n",
    "            a0_rate = (self.cost_benefit_df[mask]['a0_predicted_rating'].isin(['A', 'B', 'C'])).mean() * 100\n",
    "            a1_rate = (self.cost_benefit_df[mask]['a1_predicted_rating'].isin(['A', 'B', 'C'])).mean() * 100\n",
    "            a0_rates.append(a0_rate)\n",
    "            a1_rates.append(a1_rate)\n",
    "        \n",
    "        x = np.arange(len(clusters))\n",
    "        width = 0.35\n",
    "        \n",
    "        ax.bar(x - width/2, a0_rates, width, label='A0 (Moderate)', alpha=0.8, color='steelblue')\n",
    "        ax.bar(x + width/2, a1_rates, width, label='A1 (Ambitious)', alpha=0.8, color='coral')\n",
    "        \n",
    "        ax.set_xlabel('Cluster')\n",
    "        ax.set_ylabel('% Achieving C or Better')\n",
    "        ax.set_title('Success Rate by Cluster and Scenario')\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels([f'Cluster {c}' for c in clusters])\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.plots_dir / 'success_by_cluster.png', dpi=300)\n",
    "        plt.close()\n",
    "        \n",
    "        self.logger.info(\"Visualizations generated successfully\")\n",
    "    \n",
    "    def save_results(self) -> None:\n",
    "        \"\"\"Save all analysis results.\"\"\"\n",
    "        self.logger.info(\"Saving results...\")\n",
    "        \n",
    "        # Save scenario data\n",
    "        self.baseline_df.to_csv(\n",
    "            self.results_dir / f'baseline_scenario_{self.run_timestamp}.csv',\n",
    "            index=False\n",
    "        )\n",
    "        self.a0_scenario_df.to_csv(\n",
    "            self.results_dir / f'a0_moderate_scenario_{self.run_timestamp}.csv',\n",
    "            index=False\n",
    "        )\n",
    "        self.a1_scenario_df.to_csv(\n",
    "            self.results_dir / f'a1_ambitious_scenario_{self.run_timestamp}.csv',\n",
    "            index=False\n",
    "        )\n",
    "        \n",
    "        # Save cost-benefit analysis\n",
    "        self.cost_benefit_df.to_csv(\n",
    "            self.results_dir / f'cost_benefit_analysis_{self.run_timestamp}.csv',\n",
    "            index=False\n",
    "        )\n",
    "        \n",
    "        # Save summary statistics\n",
    "        summary_stats = self._generate_summary_statistics()\n",
    "        with open(self.results_dir / f'summary_statistics_{self.run_timestamp}.json', 'w') as f:\n",
    "            json.dump(summary_stats, f, indent=2)\n",
    "        \n",
    "        self.logger.info(f\"All results saved to: {self.run_output_dir}\")\n",
    "    \n",
    "    def _generate_summary_statistics(self) -> Dict[str, Any]:\n",
    "        \"\"\"Generate comprehensive summary statistics.\"\"\"\n",
    "        # Calculate reasonable payback statistics (exclude infinite values)\n",
    "        a0_payback_finite = self.cost_benefit_df[self.cost_benefit_df['a0_payback_years'] < 50]['a0_payback_years']\n",
    "        a1_payback_finite = self.cost_benefit_df[self.cost_benefit_df['a1_payback_years'] < 50]['a1_payback_years']\n",
    "        \n",
    "        summary = {\n",
    "            'timestamp': self.run_timestamp,\n",
    "            'total_homes_analyzed': len(self.baseline_df),\n",
    "            'available_features': {\n",
    "                'numeric_fabric': self.available_numeric_fabric,\n",
    "                'service': self.available_service,\n",
    "                'categorical_fabric': self.available_categorical_fabric\n",
    "            },\n",
    "            'feature_importance_loaded': self.feature_importance is not None,\n",
    "            'scenarios': {\n",
    "                'A0_moderate': {\n",
    "                    'homes_improved': int((self.a0_scenario_df['rating_improvement'] > 0).sum()),\n",
    "                    'achieved_c_or_better': int((self.a0_scenario_df['predicted_rating'].isin(['A', 'B', 'C'])).sum()),\n",
    "                    'average_improvement': float(self.a0_scenario_df['rating_improvement'].mean()),\n",
    "                    'average_cost': float(self.cost_benefit_df['a0_cost'].mean()),\n",
    "                    'median_cost': float(self.cost_benefit_df['a0_cost'].median()),\n",
    "                    'average_annual_savings': float(self.cost_benefit_df['a0_annual_savings'].mean()),\n",
    "                    'average_payback_years': float(a0_payback_finite.mean()) if len(a0_payback_finite) > 0 else None,\n",
    "                    'median_payback_years': float(a0_payback_finite.median()) if len(a0_payback_finite) > 0 else None,\n",
    "                },\n",
    "                'A1_ambitious': {\n",
    "                    'homes_improved': int((self.a1_scenario_df['rating_improvement'] > 0).sum()),\n",
    "                    'achieved_c_or_better': int((self.a1_scenario_df['predicted_rating'].isin(['A', 'B', 'C'])).sum()),\n",
    "                    'average_improvement': float(self.a1_scenario_df['rating_improvement'].mean()),\n",
    "                    'average_cost': float(self.cost_benefit_df['a1_cost'].mean()),\n",
    "                    'median_cost': float(self.cost_benefit_df['a1_cost'].median()),\n",
    "                    'average_annual_savings': float(self.cost_benefit_df['a1_annual_savings'].mean()),\n",
    "                    'average_payback_years': float(a1_payback_finite.mean()) if len(a1_payback_finite) > 0 else None,\n",
    "                    'median_payback_years': float(a1_payback_finite.median()) if len(a1_payback_finite) > 0 else None,\n",
    "                }\n",
    "            },\n",
    "            'model_info': {\n",
    "                'model_id': self.h2o_model.model_id if self.h2o_model else None,\n",
    "                'model_type': type(self.h2o_model).__name__ if self.h2o_model else None,\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Add rating band analysis if available\n",
    "        if hasattr(self, 'rating_cost_df') and self.rating_cost_df is not None:\n",
    "            summary['rating_band_analysis'] = self.rating_cost_df.to_dict('records')\n",
    "        \n",
    "        return summary\n",
    "    \n",
    "    def generate_report(self) -> None:\n",
    "        \"\"\"Generate comprehensive final report.\"\"\"\n",
    "        report_path = self.run_output_dir / f'scenario_analysis_report_{self.run_timestamp}.txt'\n",
    "        \n",
    "        with open(report_path, 'w') as f:\n",
    "            f.write(\"=\"*80 + \"\\n\")\n",
    "            f.write(\"EPC UPGRADE SCENARIO ANALYSIS REPORT\\n\")\n",
    "            f.write(f\"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "            f.write(\"=\"*80 + \"\\n\\n\")\n",
    "            \n",
    "            # Executive Summary\n",
    "            f.write(\"EXECUTIVE SUMMARY\\n\")\n",
    "            f.write(\"-\"*40 + \"\\n\")\n",
    "            f.write(f\"Total homes analyzed: {len(self.baseline_df)}\\n\")\n",
    "            f.write(f\"Current ratings distribution:\\n\")\n",
    "            for rating in ['D', 'E', 'F', 'G']:\n",
    "                count = (self.baseline_df['CURRENT_ENERGY_RATING'] == rating).sum()\n",
    "                f.write(f\"  {rating}: {count} ({count/len(self.baseline_df)*100:.1f}%)\\n\")\n",
    "            f.write(\"\\n\")\n",
    "            \n",
    "            # Feature importance status\n",
    "            f.write(\"FEATURE IMPORTANCE\\n\")\n",
    "            f.write(\"-\"*40 + \"\\n\")\n",
    "            if self.feature_importance is not None:\n",
    "                f.write(f\"Successfully loaded feature importance from Step 1\\n\")\n",
    "                f.write(f\"Top 5 most important features:\\n\")\n",
    "                for i, row in self.feature_importance.head(5).iterrows():\n",
    "                    f.write(f\"  - {row['feature']}: {row.get('mean_importance', 0):.2f}\\n\")\n",
    "            else:\n",
    "                f.write(\"Feature importance not available (treating all features equally)\\n\")\n",
    "            f.write(\"\\n\")\n",
    "            \n",
    "            # Scenario outcomes\n",
    "            f.write(\"SCENARIO OUTCOMES\\n\")\n",
    "            f.write(\"-\"*40 + \"\\n\")\n",
    "            \n",
    "            f.write(\"A0 (Moderate) Scenario:\\n\")\n",
    "            a0_success = (self.a0_scenario_df['predicted_rating'].isin(['A', 'B', 'C'])).sum()\n",
    "            f.write(f\"  Homes achieving C or better: {a0_success}/{len(self.a0_scenario_df)} \"\n",
    "                   f\"({a0_success/len(self.a0_scenario_df)*100:.1f}%)\\n\")\n",
    "            f.write(f\"  Average cost: £{self.cost_benefit_df['a0_cost'].mean():,.0f}\\n\")\n",
    "            f.write(f\"  Median cost: £{self.cost_benefit_df['a0_cost'].median():,.0f}\\n\")\n",
    "            f.write(f\"  Average annual savings: £{self.cost_benefit_df['a0_annual_savings'].mean():,.0f}\\n\")\n",
    "            payback_finite = self.cost_benefit_df[self.cost_benefit_df['a0_payback_years'] < 50]['a0_payback_years']\n",
    "            if len(payback_finite) > 0:\n",
    "                f.write(f\"  Average payback: {payback_finite.mean():.1f} years\\n\")\n",
    "                f.write(f\"  Median payback: {payback_finite.median():.1f} years\\n\")\n",
    "            f.write(\"\\n\")\n",
    "            \n",
    "            f.write(\"A1 (Ambitious) Scenario:\\n\")\n",
    "            a1_success = (self.a1_scenario_df['predicted_rating'].isin(['A', 'B', 'C'])).sum()\n",
    "            f.write(f\"  Homes achieving C or better: {a1_success}/{len(self.a1_scenario_df)} \"\n",
    "                   f\"({a1_success/len(self.a1_scenario_df)*100:.1f}%)\\n\")\n",
    "            f.write(f\"  Average cost: £{self.cost_benefit_df['a1_cost'].mean():,.0f}\\n\")\n",
    "            f.write(f\"  Median cost: £{self.cost_benefit_df['a1_cost'].median():,.0f}\\n\")\n",
    "            f.write(f\"  Average annual savings: £{self.cost_benefit_df['a1_annual_savings'].mean():,.0f}\\n\")\n",
    "            payback_finite = self.cost_benefit_df[self.cost_benefit_df['a1_payback_years'] < 50]['a1_payback_years']\n",
    "            if len(payback_finite) > 0:\n",
    "                f.write(f\"  Average payback: {payback_finite.mean():.1f} years\\n\")\n",
    "                f.write(f\"  Median payback: {payback_finite.median():.1f} years\\n\")\n",
    "            f.write(\"\\n\")\n",
    "            \n",
    "            # Rating band analysis (NEW)\n",
    "            if hasattr(self, 'rating_cost_df') and self.rating_cost_df is not None:\n",
    "                f.write(\"COST ANALYSIS BY INITIAL RATING\\n\")\n",
    "                f.write(\"-\"*40 + \"\\n\")\n",
    "                for _, row in self.rating_cost_df.iterrows():\n",
    "                    f.write(f\"\\n{row['rating']} → C upgrade:\\n\")\n",
    "                    f.write(f\"  Number of homes: {int(row['total_homes'])}\\n\")\n",
    "                    f.write(f\"  A0 average cost: £{row['a0_avg_cost']:,.0f}\")\n",
    "                    f.write(f\" (success rate: {row['a0_success_rate']*100:.1f}%)\\n\")\n",
    "                    f.write(f\"  A1 average cost: £{row['a1_avg_cost']:,.0f}\")\n",
    "                    f.write(f\" (success rate: {row['a1_success_rate']*100:.1f}%)\\n\")\n",
    "                f.write(\"\\n\")\n",
    "            \n",
    "            # Key findings\n",
    "            f.write(\"KEY FINDINGS\\n\")\n",
    "            f.write(\"-\"*40 + \"\\n\")\n",
    "            \n",
    "            # Cost effectiveness\n",
    "            cost_effective_a0 = (self.cost_benefit_df['a0_payback_years'] <= 10).sum()\n",
    "            cost_effective_a1 = (self.cost_benefit_df['a1_payback_years'] <= 10).sum()\n",
    "            \n",
    "            f.write(f\"1. Cost-effectiveness (≤10 year payback):\\n\")\n",
    "            f.write(f\"   - A0: {cost_effective_a0} homes ({cost_effective_a0/len(self.cost_benefit_df)*100:.1f}%)\\n\")\n",
    "            f.write(f\"   - A1: {cost_effective_a1} homes ({cost_effective_a1/len(self.cost_benefit_df)*100:.1f}%)\\n\\n\")\n",
    "            \n",
    "            # Improvement differential\n",
    "            a0_improved = (self.a0_scenario_df['rating_improvement'] > 0).sum()\n",
    "            a1_improved = (self.a1_scenario_df['rating_improvement'] > 0).sum()\n",
    "            f.write(f\"2. Improvement differential:\\n\")\n",
    "            f.write(f\"   - A0 improved: {a0_improved} homes\\n\")\n",
    "            f.write(f\"   - A1 improved: {a1_improved} homes\\n\")\n",
    "            f.write(f\"   - Additional in A1: {a1_improved - a0_improved} homes\\n\\n\")\n",
    "            \n",
    "            # Data quality notes\n",
    "            f.write(\"DATA QUALITY NOTES\\n\")\n",
    "            f.write(\"-\"*40 + \"\\n\")\n",
    "            floor_areas = pd.to_numeric(self.baseline_df['TOTAL_FLOOR_AREA'], errors='coerce')\n",
    "            f.write(f\"Floor area mean: {floor_areas.mean():.2f} sqm\\n\")\n",
    "            if floor_areas.mean() > 500:\n",
    "                f.write(\"WARNING: Floor areas may need unit conversion\\n\")\n",
    "            if 'MULTI_GLAZE_PROPORTION' in self.baseline_df.columns:\n",
    "                glazing = pd.to_numeric(self.baseline_df['MULTI_GLAZE_PROPORTION'], errors='coerce')\n",
    "                if glazing.mean() > 1:\n",
    "                    f.write(f\"Glazing proportion mean: {glazing.mean():.2f} (converted from %)\\n\")\n",
    "            f.write(\"\\n\")\n",
    "            \n",
    "            # Files generated\n",
    "            f.write(\"FILES GENERATED\\n\")\n",
    "            f.write(\"-\"*40 + \"\\n\")\n",
    "            f.write(f\"Output directory: {self.run_output_dir}\\n\")\n",
    "            f.write(\"- Scenario data files (baseline, A0, A1)\\n\")\n",
    "            f.write(\"- Cost-benefit analysis\\n\")\n",
    "            f.write(\"- Cost by rating band analysis\\n\")\n",
    "            f.write(\"- Visualization plots\\n\")\n",
    "            f.write(\"- Summary statistics (JSON)\\n\")\n",
    "            f.write(\"\\n\")\n",
    "            \n",
    "            f.write(\"=\"*80 + \"\\n\")\n",
    "            f.write(\"END OF REPORT\\n\")\n",
    "            f.write(\"=\"*80 + \"\\n\")\n",
    "        \n",
    "        self.logger.info(f\"Report saved to: {report_path}\")\n",
    "    \n",
    "    def run_analysis(self) -> Dict[str, Any]:\n",
    "        \"\"\"Run the complete scenario generation and analysis pipeline.\"\"\"\n",
    "        self.logger.info(\"Starting Scenario Generation and Impact Prediction...\")\n",
    "        self.logger.info(\"=\"*60)\n",
    "        \n",
    "        try:\n",
    "            # 1. Initialize H2O and load model\n",
    "            self.logger.info(\"Step 1: Initializing H2O and loading model...\")\n",
    "            self.init_h2o()\n",
    "            \n",
    "            # 2. Load Step 2 clustering data\n",
    "            self.logger.info(\"Step 2: Loading clustering results...\")\n",
    "            self.epc_c_data, self.substandard_data = self.load_step2_data()\n",
    "            \n",
    "            # 2.5. Run diagnostics\n",
    "            self.logger.info(\"Step 2.5: Running data diagnostics...\")\n",
    "            self.diagnose_data()\n",
    "            \n",
    "            # 3. Compute upgrade targets\n",
    "            self.logger.info(\"Step 3: Computing upgrade targets...\")\n",
    "            targets = self.compute_upgrade_targets(self.epc_c_data)\n",
    "            \n",
    "            # 4. Create upgrade scenarios\n",
    "            self.logger.info(\"Step 4: Creating upgrade scenarios...\")\n",
    "            baseline_df, a0_df, a1_df = self.create_upgrade_scenarios(\n",
    "                self.substandard_data, targets\n",
    "            )\n",
    "            \n",
    "            # 5. Predict outcomes\n",
    "            self.logger.info(\"Step 5: Predicting scenario outcomes...\")\n",
    "            self.predict_scenario_outcomes(baseline_df, a0_df, a1_df)\n",
    "            \n",
    "            # 6. Calculate costs and benefits\n",
    "            self.logger.info(\"Step 6: Calculating costs and benefits...\")\n",
    "            self.calculate_costs_and_benefits()\n",
    "            \n",
    "            # 6.5 Calculate costs by rating band (NEW)\n",
    "            self.logger.info(\"Step 6.5: Analyzing costs by rating band...\")\n",
    "            rating_cost_df = self.calculate_cost_by_rating_band()\n",
    "            self.visualize_cost_by_rating(rating_cost_df)\n",
    "            \n",
    "            # 7. Generate visualizations\n",
    "            self.logger.info(\"Step 7: Generating visualizations...\")\n",
    "            self.generate_visualizations()\n",
    "            \n",
    "            # 8. Save results\n",
    "            self.logger.info(\"Step 8: Saving results...\")\n",
    "            self.save_results()\n",
    "            \n",
    "            # 9. Generate report\n",
    "            self.logger.info(\"Step 9: Generating final report...\")\n",
    "            self.generate_report()\n",
    "            \n",
    "            self.logger.info(\"\\n\" + \"=\"*60)\n",
    "            self.logger.info(\"SCENARIO ANALYSIS COMPLETE\")\n",
    "            self.logger.info(\"=\"*60)\n",
    "            self.logger.info(f\"Results saved to: {self.run_output_dir}\")\n",
    "            \n",
    "            # Shutdown H2O\n",
    "            h2o.shutdown(prompt=False)\n",
    "            \n",
    "            return {\n",
    "                \"status\": \"success\",\n",
    "                \"homes_analyzed\": len(self.baseline_df),\n",
    "                \"a0_success_rate\": (self.a0_scenario_df['predicted_rating'].isin(['A', 'B', 'C'])).mean(),\n",
    "                \"a1_success_rate\": (self.a1_scenario_df['predicted_rating'].isin(['A', 'B', 'C'])).mean(),\n",
    "                \"a0_avg_cost\": self.cost_benefit_df['a0_cost'].mean(),\n",
    "                \"a1_avg_cost\": self.cost_benefit_df['a1_cost'].mean(),\n",
    "                \"feature_importance_loaded\": self.feature_importance is not None,\n",
    "                \"rating_band_analysis_completed\": self.rating_cost_df is not None,\n",
    "                \"output_directory\": str(self.run_output_dir)\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Analysis failed: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            \n",
    "            # Try to shutdown H2O\n",
    "            try:\n",
    "                h2o.shutdown(prompt=False)\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            return {\n",
    "                \"status\": \"failed\",\n",
    "                \"error\": str(e),\n",
    "                \"output_directory\": str(self.run_output_dir) if hasattr(self, 'run_output_dir') else None\n",
    "            }\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main execution function.\"\"\"\n",
    "    config = Config()\n",
    "    generator = ScenarioGenerator(config)\n",
    "    \n",
    "    try:\n",
    "        results = generator.run_analysis()\n",
    "        \n",
    "        if results[\"status\"] == \"success\":\n",
    "            print(f\"\\n{'='*60}\")\n",
    "            print(\"SCENARIO ANALYSIS COMPLETED SUCCESSFULLY!\")\n",
    "            print(f\"{'='*60}\")\n",
    "            print(f\"Homes analyzed: {results['homes_analyzed']}\")\n",
    "            print(f\"A0 success rate: {results['a0_success_rate']*100:.1f}%\")\n",
    "            print(f\"A1 success rate: {results['a1_success_rate']*100:.1f}%\")\n",
    "            print(f\"A0 average cost: £{results['a0_avg_cost']:,.2f}\")\n",
    "            print(f\"A1 average cost: £{results['a1_avg_cost']:,.2f}\")\n",
    "            print(f\"Feature importance loaded: {results['feature_importance_loaded']}\")\n",
    "            print(f\"Rating band analysis completed: {results['rating_band_analysis_completed']}\")\n",
    "            print(f\"Results saved to: {results['output_directory']}\")\n",
    "            print(f\"{'='*60}\")\n",
    "        else:\n",
    "            print(f\"\\nAnalysis failed: {results['error']}\")\n",
    "            \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nAnalysis interrupted by user\")\n",
    "        try:\n",
    "            h2o.shutdown(prompt=False)\n",
    "        except:\n",
    "            pass\n",
    "    except Exception as e:\n",
    "        print(f\"\\nUnexpected error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        try:\n",
    "            h2o.shutdown(prompt=False)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d60c30-482f-4966-807e-3e025f73d83a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "sys_python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
